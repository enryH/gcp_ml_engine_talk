{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Scaling up ML using Cloud ML Engine </h1>\n",
    "\n",
    "Adapted from [Notebook](https://github.com/GoogleCloudPlatform/training-data-analyst/blob/master/courses/machine_learning/cloudmle/cloudmle.ipynb) of Google Coursera Course [Serverless Machine Learning with Tensorflow on Google Cloud Platform](https://www.coursera.org/learn/serverless-machine-learning-gcp/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow==1.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "source activate gcp_dl\n",
    "TF_VERSION=$(python3 -c 'import tensorflow as tf; print(tf.__version__)')\n",
    "if $TF_VERSION != \"1.12.0\"\n",
    "then\n",
    "    pip install tensorflow==1.12\n",
    "fi\n",
    "    echo \"Found Tensorflow: $TF_VERSION\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New working directory: /home/enryh/proj_DL_models_and_pipelines_with_GCP\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "WORKINGDIR = os.getcwd()\n",
    "folders = WORKINGDIR.split('/')\n",
    "if folders.pop() == 'notebook':  # or a list: in ['notebook', 'src', etc.]\n",
    "  WORKINGDIR = '/'.join(folders)\n",
    "  print(\"New working directory: {}\".format(WORKINGDIR))\n",
    "else:\n",
    "  print(\"Current Working direcotory is kept: {}\".format(WORKINGDIR))\n",
    "os.chdir(WORKINGDIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Environment variables for project and bucket </h2>\n",
    "\n",
    "Note that:\n",
    "<ol>\n",
    "<li> Your project id is the *unique* string that identifies your project (not the project name). You can find this from the GCP Console dashboard's Home page. My dashboard reads:  \n",
    "     \n",
    "     Project ID: ml-productive-pipeline-12345\n",
    "<li> Cloud training often involves saving and restoring model files. If you don't have a bucket already, I suggest that you create one from the GCP console (because it will dynamically check whether the bucket name you want is available). A common pattern is to prefix the bucket name by the project id, so that it is unique. Also, for cost reasons, you might want to use a single region bucket. </li>\n",
    "</ol>\n",
    "\n",
    "<b>Add all detail in to [config.yaml](../config.yaml) file in main directory. Missing in public repository.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'project-id': 'ml-productive-pipeline-53122', 'region': 'europe-west1', 'bucket': 'ml-productive-pipeline-53122', 'tf-version': 1.12, 'pkg-name': 'pkg_mnist_fnn'}\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "with open(\"config.yaml\", \"r\", encoding = \"utf8\") as f:\n",
    "    config = yaml.load(f)\n",
    "    \n",
    "print(config)\n",
    "\n",
    "# # #Create config manually and save as yaml:\n",
    "# config = {}\n",
    "# config['project-id'] = 'PROJECT'  # # REPLACE WITH YOUR PROJECT ID\n",
    "# config['region'] = 'europe-west1' # Choose an available region for Cloud MLE from https://cloud.google.com/ml-engine/docs/regions.\n",
    "# config['bucket'] = 'Bucket-name'  # REPLACE WITH YOUR BUCKET NAME. Use a regional bucket in the region you selected.\n",
    "# \n",
    "# with open(\"../config_from_python.yaml\", 'wb', encoding= 'utf8') as f:\n",
    "#     yaml.dump(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to persistently add variables to the runtime of the datalab kernel, us the build in python function `os.environ`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "PROJECT = config['project-id'] \n",
    "REGION = config['region'] # Choose an available region for Cloud MLE from https://cloud.google.com/ml-engine/docs/regions.\n",
    "BUCKET = config['bucket'] # REPLACE WITH YOUR BUCKET NAME. Use a regional bucket in the region you selected.\n",
    "PKG_NAME = config['pkg-name']\n",
    "\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['BUCKET'] = BUCKET\n",
    "os.environ['REGION'] = REGION\n",
    "os.environ['TFVERSION'] = str(config['tf-version'])  # Tensorflow version 1.4 before\n",
    "os.environ['PKG_NAME'] = config['pkg-name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can access the environement variable in the terminal running this datalab session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "echo $TFVERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "Updated property [compute/region].\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud config set project $PROJECT\n",
    "gcloud config set compute/region $REGION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allow the Cloud ML Engine service account to read/write to the bucket containing training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "PROJECT_ID=$PROJECT\n",
    "AUTH_TOKEN=$(gcloud auth print-access-token)\n",
    "# echo $AUTH_TOKEN\n",
    "SVC_ACCOUNT=$(curl -X GET -H \"Content-Type: application/json\" \\\n",
    "    -H \"Authorization: Bearer $AUTH_TOKEN\" \\\n",
    "    https://ml.googleapis.com/v1/projects/${PROJECT_ID}:getConfig \\\n",
    "    | python -c \"import json; import sys; response = json.load(sys.stdin); \\\n",
    "    print(response['serviceAccount'])\")\n",
    "echo \"Current Service Account of VM: $SVC_ACCOUNT\"\n",
    "echo \"Authorizing the Cloud ML Service account $SVC_ACCOUNT to access files in Bucket: $BUCKET\"\n",
    "gsutil -m defacl ch -u $SVC_ACCOUNT:R gs://$BUCKET\n",
    "gsutil -m acl ch -u $SVC_ACCOUNT:R -r gs://$BUCKET  # error message (if bucket is empty) can be ignored\n",
    "gsutil -m acl ch -u $SVC_ACCOUNT:W gs://$BUCKET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Packaging up the code </h2>\n",
    "\n",
    "Take your code and put into a standard Python package structure, see  <a href=\"package_ml_engine/mnist_ml_engine.py\">model.py</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\"\"\r\n",
      "First try to start Cloud ML\r\n",
      "\r\n",
      "References:\r\n",
      "Basic reference for packaging the model so that ml-engine can use it:\r\n",
      "- https://github.com/GoogleCloudPlatform/training-data-analyst/tree/master/courses/machine_learning/cloudmle/taxifare\r\n",
      "MNIST-Estimator-Example:\r\n",
      "- https://codeburst.io/use-tensorflow-dnnclassifier-estimator-to-classify-mnist-dataset-a7222bf9f940\r\n",
      "\r\n",
      "ipython -i -m src.models.test_model_estimator_api.mnist_ml_engine -- --data_path=data --output_dir=src\\models\\test_model_estimator_api\\trained --train_steps=100\r\n",
      "\"\"\"\r\n",
      "\r\n",
      "import tensorflow as tf\r\n",
      "import numpy as np\r\n",
      "\r\n",
      "from .utils import load_data\r\n",
      "###############################################################################\r\n",
      "#Factor into config:\r\n",
      "N_PIXEL = 784\r\n",
      "OUTDIR = 'trained'\r\n",
      "USE_TPU = False\r\n",
      "EPOCHS = 5\r\n",
      "\r\n",
      "if USE_TPU:\r\n",
      "    _device_update = 'tpu'\r\n",
      "else:\r\n",
      "    _device_update = 'cpu'\r\n",
      "\r\n",
      "IMAGE_SIZE = 28 * 28\r\n",
      "NUM_LABELS = 10\r\n",
      "BATCH_SIZE = 128\r\n",
      "###############################################################################\r\n",
      "\r\n",
      "\r\n",
      "def parse_images(x):\r\n",
      "    return x.reshape(len(x), -1).astype('float32')\r\n",
      "\r\n",
      "\r\n",
      "def parse_labels(y):\r\n",
      "    return y.astype('int32')\r\n",
      "\r\n",
      "\r\n",
      "def numpy_input_fn(images: np.ndarray, labels: np.ndarray, mode=tf.estimator.ModeKeys.EVAL):\r\n",
      "    if mode == tf.estimator.ModeKeys.TRAIN:\r\n",
      "        _epochs = EPOCHS\r\n",
      "        _shuffle = True\r\n",
      "        _num_threads = 2\r\n",
      "    else:\r\n",
      "        _epochs = 1\r\n",
      "        _shuffle = False\r\n",
      "        _num_threads = 1\r\n",
      "\r\n",
      "    return tf.estimator.inputs.numpy_input_fn(\r\n",
      "        {'x': images},\r\n",
      "        y=labels,\r\n",
      "        batch_size=BATCH_SIZE,\r\n",
      "        num_epochs=_epochs,\r\n",
      "        # Boolean, if True shuffles the queue. Avoid shuffle at prediction time.\r\n",
      "        shuffle=_shuffle,\r\n",
      "        queue_capacity=1000,\r\n",
      "        # Integer, number of threads used for reading and enqueueing. In order to have predicted and repeatable order of reading and enqueueing, such as in prediction and evaluation mode, num_threads should be 1.\r\n",
      "        num_threads=_num_threads\r\n",
      "    )\r\n",
      "\r\n",
      "\r\n",
      "def serving_input_fn():\r\n",
      "    feature_placeholders = {\r\n",
      "        'x': tf.placeholder(tf.float32, shape=[None, N_PIXEL])\r\n",
      "    }\r\n",
      "    features = feature_placeholders\r\n",
      "    return tf.estimator.export.ServingInputReceiver(\r\n",
      "         features=features, \r\n",
      "         receiver_tensors=feature_placeholders,\r\n",
      "         receiver_tensors_alternatives=None\r\n",
      "         )\r\n",
      "\r\n",
      "\r\n",
      "def train_and_evaluate(args):\r\n",
      "    \"\"\"\r\n",
      "    Utility function for distributed training on ML-Engine\r\n",
      "    https://www.tensorflow.org/api_docs/python/tf/estimator/train_and_evaluate \r\n",
      "    \"\"\"\r\n",
      "    ##########################################\r\n",
      "    # Load Data in Memoery\r\n",
      "\r\n",
      "  # #ToDo: replace numpy-arrays\r\n",
      "    (x_train, y_train), (x_test, y_test) = load_data(\r\n",
      "        rel_path=args['data_path'])\r\n",
      "  \r\n",
      "    x_train = parse_images(x_train)\r\n",
      "    x_test = parse_images(x_test)\r\n",
      "\r\n",
      "    y_train = parse_labels(y_train)\r\n",
      "    y_test = parse_labels(y_test)\r\n",
      "\r\n",
      "    model = tf.estimator.DNNClassifier(\r\n",
      "        hidden_units=[256, 128, 64],\r\n",
      "        feature_columns=[tf.feature_column.numeric_column(\r\n",
      "            'x', shape=[N_PIXEL, ])],\r\n",
      "        model_dir=args['output_dir'],\r\n",
      "        n_classes=10,\r\n",
      "        optimizer=tf.train.AdamOptimizer,\r\n",
      "        # activation_fn=,\r\n",
      "        dropout=0.2,\r\n",
      "        batch_norm=False,\r\n",
      "        loss_reduction='weighted_sum',\r\n",
      "        warm_start_from=None\r\n",
      "    )\r\n",
      "   \r\n",
      "    train_spec = tf.estimator.TrainSpec(\r\n",
      "        input_fn=numpy_input_fn(\r\n",
      "            x_train, y_train, mode=tf.estimator.ModeKeys.TRAIN),\r\n",
      "        max_steps=args['train_steps']\r\n",
      "    )\r\n",
      "    exporter = tf.estimator.LatestExporter('exporter', serving_input_fn)\r\n",
      "    eval_spec = tf.estimator.EvalSpec(\r\n",
      "        input_fn=numpy_input_fn(\r\n",
      "            x_test, y_test, mode=tf.estimator.ModeKeys.EVAL),\r\n",
      "        steps=None,\r\n",
      "        start_delay_secs=args['eval_delay_secs'],\r\n",
      "        throttle_secs=args['min_eval_frequency'],\r\n",
      "        exporters=exporter\r\n",
      "    )\r\n",
      "    tf.estimator.train_and_evaluate(\r\n",
      "        estimator=model, train_spec=train_spec, eval_spec=eval_spec)\r\n",
      "    print((model.get_variable_names()))\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "    # model.train(input_fn=numpy_input_fn(\r\n",
      "    #     x_train, y_train, mode=tf.estimator.ModeKeys.TRAIN))\r\n",
      "    # # #######################################\r\n",
      "\r\n",
      "# How to evaluate in the cloud over a whole evaluation set?\r\n",
      "    # # # Evaluate\r\n",
      "    # metrics_train = model.evaluate(\r\n",
      "    #     input_fn=numpy_input_fn(x_train, y_train, mode=tf.estimator.ModeKeys.EVAL))\r\n",
      "    # metrics_test = model.evaluate(\r\n",
      "    #     input_fn=numpy_input_fn(\r\n",
      "    #         x_test, y_test, mode=tf.estimator.ModeKeys.EVAL)\r\n",
      "    # )\r\n",
      "    # import pandas as pd\r\n",
      "    # metrics = pd.DataFrame(\r\n",
      "    #     {'Train': metrics_train, 'Test': metrics_test}).transpose()\r\n",
      "    # print(\"## Metrics DF\\n\", metrics)\r\n",
      "    # # #######################################\r\n",
      "    # # # get individual predictions:\r\n",
      "    # predictions_iterator = model.predict(input_fn=numpy_input_fn(\r\n",
      "    #     x_test, y_test, mode=tf.estimator.ModeKeys.EVAL))\r\n",
      "    # for i, pred in enumerate(predictions_iterator):\r\n",
      "    #     if i % 999 == 0:\r\n",
      "    #         print('Image: {}'.format(i))\r\n",
      "    #         print(pred)\r\n",
      "    # #ToDo: 10000 Test-Images yield 20000 predictions?!\r\n",
      "    # predictions_iterator = model.predict(input_fn=numpy_input_fn(\r\n",
      "    #     x_test, y_test, mode=tf.estimator.ModeKeys.EVAL))\r\n",
      "    # assert len(list(predictions_iterator)) == len(x_test)\r\n"
     ]
    }
   ],
   "source": [
    "!cat src/$PKG_NAME/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\"\"\r\n",
      "Parse arguments and call main function\r\n",
      "\"\"\"\r\n",
      "import os\r\n",
      "import argparse\r\n",
      "import shutil\r\n",
      "\r\n",
      "from .model import train_and_evaluate\r\n",
      "\r\n",
      "if __name__ == '__main__':\r\n",
      "    parser = argparse.ArgumentParser()\r\n",
      "    parser.add_argument(\r\n",
      "        '--data_path',\r\n",
      "        help='GCS or local path to training data',\r\n",
      "        required=True\r\n",
      "    )\r\n",
      "    parser.add_argument(\r\n",
      "        '--output_dir',\r\n",
      "        help='GCS location to write checkpoints and export models',\r\n",
      "        required=True\r\n",
      "    )\r\n",
      "    parser.add_argument(\r\n",
      "        '--train_batch_size',\r\n",
      "        help='Batch size for training steps',\r\n",
      "        type=int,\r\n",
      "        default='128'\r\n",
      "    )\r\n",
      "    parser.add_argument(\r\n",
      "        '--train_steps',\r\n",
      "        help='Steps to run the training job for',\r\n",
      "        type=int,\r\n",
      "        default='200'\r\n",
      "    )\r\n",
      "    parser.add_argument(\r\n",
      "        '--hidden_units',\r\n",
      "        help='List of hidden layer sizes to use for DNN feature columns',\r\n",
      "        nargs='+',\r\n",
      "        type=int,\r\n",
      "        default=[128, 64, 32]\r\n",
      "    )\r\n",
      "    parser.add_argument(\r\n",
      "        '--job_dir',\r\n",
      "        help='this model ignores this field, but it is required by gcloud',\r\n",
      "        default='junk'\r\n",
      "    )\r\n",
      "    # Eval arguments\r\n",
      "    parser.add_argument(\r\n",
      "        '--eval_delay_secs',\r\n",
      "        help='How long to wait before running first evaluation',\r\n",
      "        default='10',\r\n",
      "        type=int\r\n",
      "    )\r\n",
      "    parser.add_argument(\r\n",
      "        '--min_eval_frequency',\r\n",
      "        help='Seconds between evaluations',\r\n",
      "        default=300,\r\n",
      "        type=int\r\n",
      "    )\r\n",
      "\r\n",
      "    args = parser.parse_args().__dict__\r\n",
      "\r\n",
      "    OUTDIR = args['output_dir']\r\n",
      "    # #######################################\r\n",
      "    # # Train\r\n",
      "    # ToDo execute outside from skript\r\n",
      "    shutil.rmtree(OUTDIR, ignore_errors=True)  # start fresh each time\r\n",
      "    train_and_evaluate(args)"
     ]
    }
   ],
   "source": [
    "!cat src/$PKG_NAME/task.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Find absolute paths to your data </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the absolute paths below.\n",
    "`/content` is mapped in Datalab to where the home icon takes you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working Directory /home/enryh/proj_DL_models_and_pipelines_with_GCP\n",
      "Package Directory /home/enryh/proj_DL_models_and_pipelines_with_GCP/src/pkg_mnist_fnn\n",
      "Saved Model directory to be erased: /home/enryh/proj_DL_models_and_pipelines_with_GCP/src//trained\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "echo \"Working Directory $PWD\"\n",
    "echo \"Package Directory $PWD/src/$PKG_NAME\"\n",
    "echo \"Saved Model directory to be erased: $PWD/src/$PKG_Name/trained\"\n",
    "rm -rf $PWD/src/$PKG_NAME/trained/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Running the Python module from the command-line </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Package Path: src.pkg_mnist_fnn.task\n",
      "['dnn/head/beta1_power', 'dnn/head/beta2_power', 'dnn/hiddenlayer_0/bias', 'dnn/hiddenlayer_0/bias/t_0/Adam', 'dnn/hiddenlayer_0/bias/t_0/Adam_1', 'dnn/hiddenlayer_0/kernel', 'dnn/hiddenlayer_0/kernel/t_0/Adam', 'dnn/hiddenlayer_0/kernel/t_0/Adam_1', 'dnn/hiddenlayer_1/bias', 'dnn/hiddenlayer_1/bias/t_0/Adam', 'dnn/hiddenlayer_1/bias/t_0/Adam_1', 'dnn/hiddenlayer_1/kernel', 'dnn/hiddenlayer_1/kernel/t_0/Adam', 'dnn/hiddenlayer_1/kernel/t_0/Adam_1', 'dnn/hiddenlayer_2/bias', 'dnn/hiddenlayer_2/bias/t_0/Adam', 'dnn/hiddenlayer_2/bias/t_0/Adam_1', 'dnn/hiddenlayer_2/kernel', 'dnn/hiddenlayer_2/kernel/t_0/Adam', 'dnn/hiddenlayer_2/kernel/t_0/Adam_1', 'dnn/logits/bias', 'dnn/logits/bias/t_0/Adam', 'dnn/logits/bias/t_0/Adam_1', 'dnn/logits/kernel', 'dnn/logits/kernel/t_0/Adam', 'dnn/logits/kernel/t_0/Adam_1', 'global_step']\n",
      "Saved model: /home/enryh/proj_DL_models_and_pipelines_with_GCP/src/pkg_mnist_fnn/trained/export/exporter/ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:enqueue_data was called with num_epochs and num_threads > 1. num_epochs is applied per thread, so this will produce more epochs than you probably intend. If you want to limit epochs, use one thread.\n",
      "WARNING:tensorflow:enqueue_data was called with shuffle=True, num_threads > 1, and num_epochs. This will create multiple threads, all reading the array/dataframe in order adding to the same shuffling queue; the results will likely not be sufficiently shuffled.\n",
      "WARNING:tensorflow:From /home/enryh/miniconda3/envs/gcp_dl/lib/python3.6/site-packages/tensorflow/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /home/enryh/miniconda3/envs/gcp_dl/lib/python3.6/site-packages/tensorflow/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "2019-02-18 11:49:15.193946: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2019-02-18 11:49:15.198531: I tensorflow/core/common_runtime/process_util.cc:69] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "WARNING:tensorflow:From /home/enryh/miniconda3/envs/gcp_dl/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py:804: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:Export includes no default signature!\n",
      "WARNING:tensorflow:From /home/enryh/miniconda3/envs/gcp_dl/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py:1044: calling SavedModelBuilder.add_meta_graph_and_variables (from tensorflow.python.saved_model.builder_impl) with legacy_init_op is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Pass your op to the equivalent parameter main_op instead.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "rm -rf $PKG_NAME.tar.gz ${PWD}/$PKG_NAME/trained\n",
    "export PYTHONPATH=${PYTHONPATH}:${PWD}/../\n",
    "\n",
    "echo \"Python Package Path: src.${PKG_NAME}.task\"\n",
    "\n",
    "python -m src.${PKG_NAME}.task \\\n",
    "   --data_path=\"${PWD}/data\" \\\n",
    "   --output_dir=${PWD}/src/${PKG_NAME}/trained \\\n",
    "   --train_steps=1000 \\\n",
    "   --job_dir=tmp\n",
    "   \n",
    "echo \"Saved model: ${PWD}/src/${PKG_NAME}/trained/export/exporter/ \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1550486967\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ls $PWD/src/$PKG_NAME/trained/export/exporter/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an test-image in numpy format saved as json (copy from test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data from /home/enryh/proj_DL_models_and_pipelines_with_GCP/data/mnist.npz\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from src.pkg_mnist_fnn.utils import load_data\n",
    "from src.pkg_mnist_fnn.model import parse_images\n",
    "(_,_), (x_test, y_test) = load_data(rel_path='data')\n",
    "N=4\n",
    "test_indices = np.random.randint(low=0, high=len(y_test), size=N)\n",
    "x_test, y_test = x_test[test_indices], y_test[test_indices]\n",
    "x_test = parse_images(x_test).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "eol = \"\\r\\n\"\n",
    "n_lines = len(y_test)\n",
    "with open(\"data/test.json\", \"w\") as f:\n",
    "    for image, label in zip(x_test, y_test):\n",
    "        _dict = {\"x\": image} #, \"y\": int(label)}\n",
    "        f.write(json.dumps(_dict) + eol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "with open(\"data/test.json\", \"r\") as f:\n",
    "    images = f.readlines()\n",
    "plt.figure(figsize=(20,4))\n",
    "for i, image in enumerate(images):\n",
    "    if i < 4:\n",
    "        image = json.loads(image)\n",
    "        image = np.array(image['x'])\n",
    "        plt.subplot(1, 5, i+1)\n",
    "        plt.imshow(np.reshape(image, (28,28)), cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /usr/lib/google-cloud-sdk/lib/googlecloudsdk/command_lib/ml_engine/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to work with `Python 3`, delete the `*.pyc` files, see [post](https://stackoverflow.com/questions/48824381/gcloud-ml-engine-local-predict-runtimeerror-bad-magic-number-in-pyc-file)\n",
    "\n",
    "Default Datalab\n",
    "```\n",
    "rm /tools/google-cloud-sdk/lib/googlecloudsdk/command_lib/ml_engine/*.pyc\n",
    "```\n",
    "Default UNIX:\n",
    "```\n",
    "sudo rm /usr/lib/google-cloud-sdk/lib/googlecloudsdk/command_lib/ml_engine/*.pyc\n",
    "```\n",
    "\n",
    "> Process running Datalab or Jupyter Notebook needs admin rights. This is not always given for locally run notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# #remove any pyc files: Using Python3 you have to recompile\n",
    "# #Note: you need admin rights\n",
    "rm /tools/google-cloud-sdk/lib/googlecloudsdk/command_lib/ml_engine/*.pyc\n",
    "# sudo rm /usr/lib/google-cloud-sdk/lib/googlecloudsdk/command_lib/ml_engine/*.pyc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Model:  1550484398\n",
      "CLASS_IDS  CLASSES  LOGITS                                                                                                                                                                                                        PROBABILITIES\n",
      "[4]        [u'4']   [0.2955600619316101, -1.395798683166504, -1.8033928871154785, -0.07336592674255371, 4.363767623901367, 1.0356162786483765, -3.5050811767578125, 1.4503240585327148, 0.24793429672718048, 3.1991055011749268]  [0.011773805133998394, 0.0021695473697036505, 0.001443288754671812, 0.008141309022903442, 0.6882036924362183, 0.024678530171513557, 0.0002632203104440123, 0.037361521273851395, 0.011226214468479156, 0.2147388756275177]\n",
      "[9]        [u'9']   [-0.6732280850410461, -5.111705780029297, -1.8348519802093506, -0.9554049372673035, 1.238022804260254, 0.11140099167823792, -5.326626777648926, 1.729777216911316, -0.345848023891449, 3.9755911827087402]    [0.007815743796527386, 9.233446326106787e-05, 0.002446153201162815, 0.005894169677048922, 0.05284649133682251, 0.017128940671682358, 7.447752432199195e-05, 0.0864136591553688, 0.010843006893992424, 0.8164450526237488]\n",
      "[2]        [u'2']   [-6.009137153625488, -3.665865898132324, 11.587852478027344, 3.1798863410949707, -3.0333058834075928, -4.280998706817627, -1.3579951524734497, -1.183574914932251, 4.8169965744018555, -1.2152471542358398]   [2.2757609130508172e-08, 2.37026000604601e-07, 0.9986233711242676, 0.00022277591051533818, 4.4618320771405706e-07, 1.2812900251901738e-07, 2.382821776336641e-06, 2.836882686096942e-06, 0.0011451342143118382, 2.7484397833177354e-06]\n",
      "[5]        [u'5']   [1.3700165748596191, -7.255740642547607, -4.728294372558594, -1.0182626247406006, 4.566244602203369, 6.888350963592529, -1.4476794004440308, 0.14910955727100372, 2.2279152870178223, 5.0454840660095215]     [0.003155231010168791, 5.661251520905353e-07, 7.088725851644995e-06, 0.0002896108489949256, 0.07711438089609146, 0.7863454222679138, 0.00018850441847462207, 0.0009306747233495116, 0.007440666668117046, 0.12452783435583115]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG: Running [gcloud.ml-engine.local.predict] with arguments: [--json-instances: \"./data/test.json\", --model-dir: \"/home/enryh/proj_DL_models_and_pipelines_with_GCP/src/pkg_mnist_fnn/trained/export/exporter/1550484398\", --verbosity: \"debug\"]\n",
      "WARNING: 2019-02-18 11:20:57.330275: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2019-02-18 11:20:57.335174: I tensorflow/core/common_runtime/process_util.cc:69] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "\n",
      "INFO: Display format: \"default \n",
      "          table(\n",
      "              predictions:format=\"table(\n",
      "                  class_ids, classes, logits, probabilities\n",
      "              )\"\n",
      "          )\"\n",
      "DEBUG: SDK update checks are disabled.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "model_dir=$(ls $PWD/src/$PKG_NAME/trained/export/exporter/)\n",
    "echo \"Selected Model:  $model_dir\"\n",
    "gcloud ml-engine local predict \\\n",
    "    --model-dir=${PWD}/src/$PKG_NAME/trained/export/exporter/${model_dir} \\\n",
    "    --json-instances=./data/test.json \\\n",
    "    --verbosity debug > data/test_predictions\n",
    "cat data/test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 9 2 5]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME\n",
      "    gcloud ml-engine local predict - run prediction locally\n",
      "\n",
      "SYNOPSIS\n",
      "    gcloud ml-engine local predict --model-dir=MODEL_DIR\n",
      "        (--json-instances=JSON_INSTANCES | --text-instances=TEXT_INSTANCES)\n",
      "        [--framework=FRAMEWORK] [--signature-name=SIGNATURE_NAME]\n",
      "        [GCLOUD_WIDE_FLAG ...]\n",
      "\n",
      "DESCRIPTION\n",
      "    gcloud ml-engine local predict performs prediction locally with the given\n",
      "    instances. It requires the TensorFlow SDK be installed locally. The output\n",
      "    format mirrors gcloud ml-engine predict (online prediction)\n",
      "\n",
      "REQUIRED FLAGS\n",
      "     --model-dir=MODEL_DIR\n",
      "        Path to the model.\n",
      "\n",
      "     Exactly one of these must be specified:\n",
      "\n",
      "       --json-instances=JSON_INSTANCES\n",
      "          Path to a local file from which instances are read. Instances are in\n",
      "          JSON format; newline delimited.\n",
      "\n",
      "          An example of the JSON instances file:\n",
      "\n",
      "              {\"images\": [0.0, ..., 0.1], \"key\": 3}\n",
      "              {\"images\": [0.0, ..., 0.1], \"key\": 2}\n",
      "              ...\n",
      "\n",
      "          This flag accepts \"-\" for stdin.\n",
      "\n",
      "       --text-instances=TEXT_INSTANCES\n",
      "          Path to a local file from which instances are read. Instances are in\n",
      "          UTF-8 encoded text format; newline delimited.\n",
      "\n",
      "          An example of the text instances file:\n",
      "\n",
      "              107,4.9,2.5,4.5,1.7\n",
      "              100,5.7,2.8,4.1,1.3\n",
      "              ...\n",
      "\n",
      "          This flag accepts \"-\" for stdin.\n",
      "\n",
      "OPTIONAL FLAGS\n",
      "     --framework=FRAMEWORK\n",
      "        The ML framework used to train this version of the model. If not\n",
      "        specified, defaults to tensorflow. FRAMEWORK must be one of:\n",
      "        scikit-learn, tensorflow, xgboost.\n",
      "\n",
      "     --signature-name=SIGNATURE_NAME\n",
      "        The name of the signature defined in the SavedModel to use for this\n",
      "        job. Defaults to DEFAULT_SERVING_SIGNATURE_DEF_KEY in\n",
      "        https://www.tensorflow.org/api_docs/python/tf/saved_model/signature_constants,\n",
      "        which is \"serving_default\". Only applies to TensorFlow models.\n",
      "\n",
      "GCLOUD WIDE FLAGS\n",
      "    These flags are available to all commands: --account, --configuration,\n",
      "    --flatten, --format, --help, --log-http, --project, --quiet, --trace-token,\n",
      "    --user-output-enabled, --verbosity. Run $ gcloud help for details.\n",
      "\n",
      "NOTES\n",
      "    These variants are also available:\n",
      "\n",
      "        $ gcloud alpha ml-engine local predict\n",
      "        $ gcloud beta ml-engine local predict\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud ml-engine local predict --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Running locally using gcloud </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dnn/head/beta1_power', 'dnn/head/beta2_power', 'dnn/hiddenlayer_0/bias', 'dnn/hiddenlayer_0/bias/t_0/Adam', 'dnn/hiddenlayer_0/bias/t_0/Adam_1', 'dnn/hiddenlayer_0/kernel', 'dnn/hiddenlayer_0/kernel/t_0/Adam', 'dnn/hiddenlayer_0/kernel/t_0/Adam_1', 'dnn/hiddenlayer_1/bias', 'dnn/hiddenlayer_1/bias/t_0/Adam', 'dnn/hiddenlayer_1/bias/t_0/Adam_1', 'dnn/hiddenlayer_1/kernel', 'dnn/hiddenlayer_1/kernel/t_0/Adam', 'dnn/hiddenlayer_1/kernel/t_0/Adam_1', 'dnn/hiddenlayer_2/bias', 'dnn/hiddenlayer_2/bias/t_0/Adam', 'dnn/hiddenlayer_2/bias/t_0/Adam_1', 'dnn/hiddenlayer_2/kernel', 'dnn/hiddenlayer_2/kernel/t_0/Adam', 'dnn/hiddenlayer_2/kernel/t_0/Adam_1', 'dnn/logits/bias', 'dnn/logits/bias/t_0/Adam', 'dnn/logits/bias/t_0/Adam_1', 'dnn/logits/kernel', 'dnn/logits/kernel/t_0/Adam', 'dnn/logits/kernel/t_0/Adam_1', 'global_step']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:enqueue_data was called with num_epochs and num_threads > 1. num_epochs is applied per thread, so this will produce more epochs than you probably intend. If you want to limit epochs, use one thread.\n",
      "WARNING:tensorflow:enqueue_data was called with shuffle=True, num_threads > 1, and num_epochs. This will create multiple threads, all reading the array/dataframe in order adding to the same shuffling queue; the results will likely not be sufficiently shuffled.\n",
      "WARNING:tensorflow:From /home/enryh/miniconda3/envs/gcp_dl/lib/python3.6/site-packages/tensorflow/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /home/enryh/miniconda3/envs/gcp_dl/lib/python3.6/site-packages/tensorflow/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "2019-02-18 11:21:45.778736: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2019-02-18 11:21:45.785785: I tensorflow/core/common_runtime/process_util.cc:69] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "WARNING:tensorflow:From /home/enryh/miniconda3/envs/gcp_dl/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py:804: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:Export includes no default signature!\n",
      "WARNING:tensorflow:From /home/enryh/miniconda3/envs/gcp_dl/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py:1044: calling SavedModelBuilder.add_meta_graph_and_variables (from tensorflow.python.saved_model.builder_impl) with legacy_init_op is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Pass your op to the equivalent parameter main_op instead.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# rm -rf taxifare.tar.gz taxi_trained\n",
    "gcloud ml-engine local train \\\n",
    "   --module-name=${PKG_NAME}.task \\\n",
    "   --package-path=${PWD}/src/${PKG_NAME} \\\n",
    "   -- \\\n",
    "   --data_path=\"${PWD}/data\" \\\n",
    "   --output_dir=${PWD}/src/${PKG_NAME}/trained \\\n",
    "   --train_steps=500 \\\n",
    "   --job_dir=./tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise in TensorBoard\n",
    "\n",
    "In Datalab Tensorboard is available using a special package. On your local machine, you can execute tensorflow using the command line.\n",
    "\n",
    "DATALAB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.datalab.ml import TensorBoard\n",
    "TensorBoard().start(('{}/'+os.environ['PKG_NAME']).format(os.environ['PWD']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pid in TensorBoard.list()['pid']:\n",
    "  TensorBoard().stop(pid)\n",
    "  print('Stopped TensorBoard with pid {}'.format(pid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Local Machine: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mW0218 13:54:57.334849 Reloader tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[0mW0218 13:54:57.334848 140204896913152 tf_logging.py:120] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
      "\u001b[33mW0218 13:54:57.335278 Reloader tf_logging.py:120] Found more than one metagraph event per run. Overwriting the metagraph with the newest event.\n",
      "\u001b[0mW0218 13:54:57.335278 140204896913152 tf_logging.py:120] Found more than one metagraph event per run. Overwriting the metagraph with the newest event.\n",
      "TensorBoard 1.12.0 at http://enryh:6006 (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir $PWD/src/$PKG_NAME/trained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the above step (to stop TensorBoard) appears stalled, just move on to the next step. You don't need to wait for it to return."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Submit training job using gcloud </h2>\n",
    "\n",
    "First copy the training data to the cloud.  Then, launch a training job.\n",
    "\n",
    "After you submit the job, go to the cloud console (http://console.cloud.google.com) and select <b>Machine Learning | Jobs</b> to monitor progress.  \n",
    "\n",
    "<b>Note:</b> Don't be concerned if the notebook stalls (with a blue progress bar) or returns with an error about being unable to refresh auth tokens. This is a long-lived Cloud job and work is going on in the cloud.  Use the Cloud Console link (above) to monitor the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CommandException: 1 files/objects could not be removed.\r\n"
     ]
    }
   ],
   "source": [
    "!gsutil -m rm -rf gs://$BUCKET/$PKG_NAME/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of epochs using 10000 steps: 21.3\n",
      "For ten epochs specify 4688 steps\n"
     ]
    }
   ],
   "source": [
    "steps = 10000\n",
    "batch_size = 128\n",
    "n_train = 60000\n",
    "print(\"Number of epochs using {} steps: {:.1f}\".format(steps, steps * batch_size / n_train))\n",
    "steps = int(60000 / 128 * 10) + 1\n",
    "print(\"For ten epochs specify {} steps\".format(steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTDIR = '/'.join(['gs:/', BUCKET, PKG_NAME, 'trained'])\n",
    "os.environ['OUTDIR'] = OUTDIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process is interrupted.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "OUTDIR=gs://${BUCKET}/$PKG_NAME/trained\n",
    "JOBNAME=mnist_$(date -u +%y%m%d_%H%M%S)\n",
    "echo $OUTDIR $REGION $JOBNAME\n",
    "gsutil -m rm -rf $OUTDIR\n",
    "gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "   --region=$REGION \\\n",
    "   --module-name=$PKG_NAME.task \\\n",
    "   --package-path=${PWD}/src/$PKG_NAME \\\n",
    "   --staging-bucket=gs://$BUCKET \\\n",
    "   --scale-tier=BASIC \\\n",
    "   --python-version 3.5 \\\n",
    "   --runtime-version=$TFVERSION \\\n",
    "   -- \\\n",
    "   --data_path=\"gs://${BUCKET}/$PKG_NAME/\" \\\n",
    "   --output_dir=$OUTDIR \\\n",
    "   --train_steps=5000 \\\n",
    "   --job_dir=$OUTDIR/jobs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "createTime: '2019-02-18T10:50:11Z'\n",
      "etag: vvITuWEjDLQ=\n",
      "jobId: mnist_190218_105007\n",
      "startTime: '2019-02-18T10:50:59Z'\n",
      "state: RUNNING\n",
      "trainingInput:\n",
      "  args:\n",
      "  - --data_path=gs://ml-productive-pipeline-53122/pkg_mnist_fnn/\n",
      "  - --output_dir=gs://ml-productive-pipeline-53122/pkg_mnist_fnn/trained\n",
      "  - --train_steps=5000\n",
      "  - --job_dir=gs://ml-productive-pipeline-53122/pkg_mnist_fnn/trained/jobs\n",
      "  packageUris:\n",
      "  - gs://ml-productive-pipeline-53122/mnist_190218_105007/cac4d120b8857d8007d507feb554bfa3f8c883df822b1a7e4ef5e547e84f4088/pkg_mnist_fnn-0.0.0.tar.gz\n",
      "  pythonModule: pkg_mnist_fnn.task\n",
      "  pythonVersion: '3.5'\n",
      "  region: europe-west1\n",
      "  runtimeVersion: '1.12'\n",
      "trainingOutput: {}\n",
      "INFO\t2019-02-18 11:50:11 +0100\tservice\t\tValidating job requirements...\n",
      "INFO\t2019-02-18 11:50:11 +0100\tservice\t\tJob creation request has been successfully validated.\n",
      "INFO\t2019-02-18 11:50:11 +0100\tservice\t\tJob mnist_190218_105007 is queued.\n",
      "INFO\t2019-02-18 11:50:12 +0100\tservice\t\tWaiting for job to be provisioned.\n",
      "INFO\t2019-02-18 11:50:16 +0100\tservice\t\tWaiting for training program to start.\n",
      "INFO\t2019-02-18 11:51:28 +0100\tmaster-replica-0\t\tRunning task with arguments: --cluster={\"master\": [\"127.0.0.1:2222\"]} --task={\"type\": \"master\", \"index\": 0} --job={  \"package_uris\": [\"gs://ml-productive-pipeline-53122/mnist_190218_105007/cac4d120b8857d8007d507feb554bfa3f8c883df822b1a7e4ef5e547e84f4088/pkg_mnist_fnn-0.0.0.tar.gz\"],  \"python_module\": \"pkg_mnist_fnn.task\",  \"args\": [\"--data_path\\u003dgs://ml-productive-pipeline-53122/pkg_mnist_fnn/\", \"--output_dir\\u003dgs://ml-productive-pipeline-53122/pkg_mnist_fnn/trained\", \"--train_steps\\u003d5000\", \"--job_dir\\u003dgs://ml-productive-pipeline-53122/pkg_mnist_fnn/trained/jobs\"],  \"region\": \"europe-west1\",  \"runtime_version\": \"1.12\",  \"run_on_raw_vm\": true,  \"python_version\": \"3.5\"}\n",
      "INFO\t2019-02-18 11:51:36 +0100\tmaster-replica-0\t\tRunning module pkg_mnist_fnn.task.\n",
      "INFO\t2019-02-18 11:51:36 +0100\tmaster-replica-0\t\tDownloading the package: gs://ml-productive-pipeline-53122/mnist_190218_105007/cac4d120b8857d8007d507feb554bfa3f8c883df822b1a7e4ef5e547e84f4088/pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-02-18 11:51:36 +0100\tmaster-replica-0\t\tRunning command: gsutil -q cp gs://ml-productive-pipeline-53122/mnist_190218_105007/cac4d120b8857d8007d507feb554bfa3f8c883df822b1a7e4ef5e547e84f4088/pkg_mnist_fnn-0.0.0.tar.gz pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-02-18 11:51:38 +0100\tmaster-replica-0\t\tInstalling the package: gs://ml-productive-pipeline-53122/mnist_190218_105007/cac4d120b8857d8007d507feb554bfa3f8c883df822b1a7e4ef5e547e84f4088/pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-02-18 11:51:38 +0100\tmaster-replica-0\t\tRunning command: pip3 install --user --upgrade --force-reinstall --no-deps pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-02-18 11:51:40 +0100\tmaster-replica-0\t\tProcessing ./pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-02-18 11:51:41 +0100\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-02-18 11:51:41 +0100\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-02-18 11:51:41 +0100\tmaster-replica-0\t\tBuilding wheels for collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-02-18 11:51:41 +0100\tmaster-replica-0\t\t  Building wheel for pkg-mnist-fnn (setup.py): started\n",
      "INFO\t2019-02-18 11:51:42 +0100\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-02-18 11:51:42 +0100\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-02-18 11:51:42 +0100\tmaster-replica-0\t\t  Building wheel for pkg-mnist-fnn (setup.py): finished with status 'done'\n",
      "INFO\t2019-02-18 11:51:42 +0100\tmaster-replica-0\t\t  Stored in directory: /root/.cache/pip/wheels/1a/07/69/18074b1e4bd022717a0b95df967868ee8c62b8952276f00a53\n",
      "INFO\t2019-02-18 11:51:42 +0100\tmaster-replica-0\t\tSuccessfully built pkg-mnist-fnn\n",
      "INFO\t2019-02-18 11:51:42 +0100\tmaster-replica-0\t\tInstalling collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-02-18 11:51:42 +0100\tmaster-replica-0\t\tSuccessfully installed pkg-mnist-fnn-0.0.0\n",
      "ERROR\t2019-02-18 11:51:42 +0100\tmaster-replica-0\t\tYou are using pip version 19.0.1, however version 19.0.2 is available.\n",
      "ERROR\t2019-02-18 11:51:42 +0100\tmaster-replica-0\t\tYou should consider upgrading via the 'pip install --upgrade pip' command.\n",
      "INFO\t2019-02-18 11:51:42 +0100\tmaster-replica-0\t\tRunning command: pip3 install --user pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-02-18 11:51:43 +0100\tmaster-replica-0\t\tProcessing ./pkg_mnist_fnn-0.0.0.tar.gz\n",
      "INFO\t2019-02-18 11:51:43 +0100\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-02-18 11:51:43 +0100\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-02-18 11:51:43 +0100\tmaster-replica-0\t\tBuilding wheels for collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-02-18 11:51:43 +0100\tmaster-replica-0\t\t  Building wheel for pkg-mnist-fnn (setup.py): started\n",
      "INFO\t2019-02-18 11:51:43 +0100\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2019-02-18 11:51:43 +0100\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2019-02-18 11:51:44 +0100\tmaster-replica-0\t\t  Building wheel for pkg-mnist-fnn (setup.py): finished with status 'done'\n",
      "INFO\t2019-02-18 11:51:44 +0100\tmaster-replica-0\t\t  Stored in directory: /root/.cache/pip/wheels/1a/07/69/18074b1e4bd022717a0b95df967868ee8c62b8952276f00a53\n",
      "INFO\t2019-02-18 11:51:44 +0100\tmaster-replica-0\t\tSuccessfully built pkg-mnist-fnn\n",
      "INFO\t2019-02-18 11:51:45 +0100\tmaster-replica-0\t\tInstalling collected packages: pkg-mnist-fnn\n",
      "INFO\t2019-02-18 11:51:45 +0100\tmaster-replica-0\t\t  Found existing installation: pkg-mnist-fnn 0.0.0\n",
      "INFO\t2019-02-18 11:51:45 +0100\tmaster-replica-0\t\t    Uninstalling pkg-mnist-fnn-0.0.0:\n",
      "INFO\t2019-02-18 11:51:45 +0100\tmaster-replica-0\t\t      Successfully uninstalled pkg-mnist-fnn-0.0.0\n",
      "INFO\t2019-02-18 11:51:45 +0100\tmaster-replica-0\t\tSuccessfully installed pkg-mnist-fnn-0.0.0\n",
      "ERROR\t2019-02-18 11:51:45 +0100\tmaster-replica-0\t\tYou are using pip version 19.0.1, however version 19.0.2 is available.\n",
      "ERROR\t2019-02-18 11:51:45 +0100\tmaster-replica-0\t\tYou should consider upgrading via the 'pip install --upgrade pip' command.\n",
      "INFO\t2019-02-18 11:51:45 +0100\tmaster-replica-0\t\tRunning command: python3 -m pkg_mnist_fnn.task --data_path=gs://ml-productive-pipeline-53122/pkg_mnist_fnn/ --output_dir=gs://ml-productive-pipeline-53122/pkg_mnist_fnn/trained --train_steps=5000 --job_dir=gs://ml-productive-pipeline-53122/pkg_mnist_fnn/trained/jobs\n",
      "INFO\t2019-02-18 11:51:49 +0100\tmaster-replica-0\t\tDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "INFO\t2019-02-18 11:51:49 +0100\tmaster-replica-0\t\t    8192/11490434 [..............................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-02-18 11:51:49 +0100\tmaster-replica-0\t\t 4202496/11490434 [=========>....................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-02-18 11:51:49 +0100\tmaster-replica-0\t\t10280960/11490434 [=========================>....] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "INFO\t2019-02-18 11:51:49 +0100\tmaster-replica-0\t\t11493376/11490434 [==============================] - 0s 0us/step\n",
      "INFO\t2019-02-18 11:51:50 +0100\tmaster-replica-0\t\tTF_CONFIG environment variable: {'environment': 'cloud', 'job': {'package_uris': ['gs://ml-productive-pipeline-53122/mnist_190218_105007/cac4d120b8857d8007d507feb554bfa3f8c883df822b1a7e4ef5e547e84f4088/pkg_mnist_fnn-0.0.0.tar.gz'], 'python_module': 'pkg_mnist_fnn.task', 'region': 'europe-west1', 'args': ['--data_path=gs://ml-productive-pipeline-53122/pkg_mnist_fnn/', '--output_dir=gs://ml-productive-pipeline-53122/pkg_mnist_fnn/trained', '--train_steps=5000', '--job_dir=gs://ml-productive-pipeline-53122/pkg_mnist_fnn/trained/jobs'], 'python_version': '3.5', 'run_on_raw_vm': True, 'runtime_version': '1.12'}, 'cluster': {'master': ['127.0.0.1:2222']}, 'task': {'cloud': 'qe913eccfb8ab063b-ml', 'type': 'master', 'index': 0}}\n",
      "INFO\t2019-02-18 11:51:50 +0100\tmaster-replica-0\t\tUsing default config.\n",
      "INFO\t2019-02-18 11:51:50 +0100\tmaster-replica-0\t\tUsing config: {'_save_checkpoints_steps': None, '_global_id_in_cluster': 0, '_experimental_distribute': None, '_task_type': 'master', '_keep_checkpoint_every_n_hours': 10000, '_device_fn': None, '_session_config': device_filters: \"/job:ps\"\n",
      "INFO\t2019-02-18 11:51:50 +0100\tmaster-replica-0\t\tdevice_filters: \"/job:master\"\n",
      "INFO\t2019-02-18 11:51:50 +0100\tmaster-replica-0\t\tallow_soft_placement: true\n",
      "INFO\t2019-02-18 11:51:50 +0100\tmaster-replica-0\t\tgraph_options {\n",
      "INFO\t2019-02-18 11:51:50 +0100\tmaster-replica-0\t\t  rewrite_options {\n",
      "INFO\t2019-02-18 11:51:50 +0100\tmaster-replica-0\t\t    meta_optimizer_iterations: ONE\n",
      "INFO\t2019-02-18 11:51:50 +0100\tmaster-replica-0\t\t  }\n",
      "INFO\t2019-02-18 11:51:50 +0100\tmaster-replica-0\t\t}\n",
      "INFO\t2019-02-18 11:51:50 +0100\tmaster-replica-0\t\t, '_eval_distribute': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7feb9507d898>, '_protocol': None, '_task_id': 0, '_model_dir': 'gs://ml-productive-pipeline-53122/pkg_mnist_fnn/trained', '_num_worker_replicas': 1, '_train_distribute': None, '_num_ps_replicas': 0, '_is_chief': True, '_keep_checkpoint_max': 5, '_tf_random_seed': None, '_save_checkpoints_secs': 600, '_service': None, '_save_summary_steps': 100, '_master': '', '_log_step_count_steps': 100, '_evaluation_master': ''}\n",
      "INFO\t2019-02-18 11:51:50 +0100\tmaster-replica-0\t\tNot using Distribute Coordinator.\n",
      "INFO\t2019-02-18 11:51:50 +0100\tmaster-replica-0\t\tSkip starting Tensorflow server as there is only one node in the cluster.\n",
      "WARNING\t2019-02-18 11:51:51 +0100\tmaster-replica-0\t\tenqueue_data was called with num_epochs and num_threads > 1. num_epochs is applied per thread, so this will produce more epochs than you probably intend. If you want to limit epochs, use one thread.\n",
      "WARNING\t2019-02-18 11:51:51 +0100\tmaster-replica-0\t\tenqueue_data was called with shuffle=True, num_threads > 1, and num_epochs. This will create multiple threads, all reading the array/dataframe in order adding to the same shuffling queue; the results will likely not be sufficiently shuffled.\n",
      "WARNING\t2019-02-18 11:51:51 +0100\tmaster-replica-0\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-02-18 11:51:51 +0100\tmaster-replica-0\t\tInstructions for updating:\n",
      "WARNING\t2019-02-18 11:51:51 +0100\tmaster-replica-0\t\tTo construct input pipelines, use the `tf.data` module.\n",
      "WARNING\t2019-02-18 11:51:51 +0100\tmaster-replica-0\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-02-18 11:51:51 +0100\tmaster-replica-0\t\tInstructions for updating:\n",
      "WARNING\t2019-02-18 11:51:51 +0100\tmaster-replica-0\t\tTo construct input pipelines, use the `tf.data` module.\n",
      "INFO\t2019-02-18 11:51:51 +0100\tmaster-replica-0\t\tCalling model_fn.\n",
      "INFO\t2019-02-18 11:51:52 +0100\tmaster-replica-0\t\tDone calling model_fn.\n",
      "INFO\t2019-02-18 11:51:52 +0100\tmaster-replica-0\t\tCreate CheckpointSaverHook.\n",
      "INFO\t2019-02-18 11:51:57 +0100\tmaster-replica-0\t\tGraph was finalized.\n",
      "INFO\t2019-02-18 11:51:57 +0100\tmaster-replica-0\t\tYour CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "INFO\t2019-02-18 11:51:57 +0100\tmaster-replica-0\t\tRunning local_init_op.\n",
      "INFO\t2019-02-18 11:51:57 +0100\tmaster-replica-0\t\tDone running local_init_op.\n",
      "WARNING\t2019-02-18 11:51:57 +0100\tmaster-replica-0\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py:804: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-02-18 11:51:57 +0100\tmaster-replica-0\t\tInstructions for updating:\n",
      "WARNING\t2019-02-18 11:51:57 +0100\tmaster-replica-0\t\tTo construct input pipelines, use the `tf.data` module.\n",
      "INFO\t2019-02-18 11:52:00 +0100\tmaster-replica-0\t\tSaving checkpoints for 0 into gs://ml-productive-pipeline-53122/pkg_mnist_fnn/trained/model.ckpt.\n",
      "INFO\t2019-02-18 11:52:16 +0100\tmaster-replica-0\t\tloss = 21020.336, step = 1\n",
      "INFO\t2019-02-18 11:52:18 +0100\tmaster-replica-0\t\tglobal_step/sec: 78.6377\n",
      "INFO\t2019-02-18 11:52:18 +0100\tmaster-replica-0\t\tloss = 378.62857, step = 101 (1.273 sec)\n",
      "INFO\t2019-02-18 11:52:19 +0100\tmaster-replica-0\t\tglobal_step/sec: 112.205\n",
      "INFO\t2019-02-18 11:52:19 +0100\tmaster-replica-0\t\tloss = 213.95734, step = 201 (0.891 sec)\n",
      "INFO\t2019-02-18 11:52:19 +0100\tmaster-replica-0\t\tglobal_step/sec: 121.735\n",
      "INFO\t2019-02-18 11:52:19 +0100\tmaster-replica-0\t\tloss = 140.99504, step = 301 (0.822 sec)\n",
      "INFO\t2019-02-18 11:52:20 +0100\tmaster-replica-0\t\tglobal_step/sec: 108.659\n",
      "INFO\t2019-02-18 11:52:20 +0100\tmaster-replica-0\t\tloss = 150.20166, step = 401 (0.920 sec)\n",
      "INFO\t2019-02-18 11:52:21 +0100\tmaster-replica-0\t\tglobal_step/sec: 95.2181\n",
      "INFO\t2019-02-18 11:52:21 +0100\tmaster-replica-0\t\tloss = 94.12981, step = 501 (1.051 sec)\n",
      "INFO\t2019-02-18 11:52:22 +0100\tmaster-replica-0\t\tglobal_step/sec: 114.359\n",
      "INFO\t2019-02-18 11:52:22 +0100\tmaster-replica-0\t\tloss = 66.368744, step = 601 (0.873 sec)\n",
      "INFO\t2019-02-18 11:52:23 +0100\tmaster-replica-0\t\tglobal_step/sec: 123.446\n",
      "INFO\t2019-02-18 11:52:23 +0100\tmaster-replica-0\t\tloss = 57.992844, step = 701 (0.810 sec)\n",
      "INFO\t2019-02-18 11:52:24 +0100\tmaster-replica-0\t\tglobal_step/sec: 115.831\n",
      "INFO\t2019-02-18 11:52:24 +0100\tmaster-replica-0\t\tloss = 62.30481, step = 801 (0.864 sec)\n",
      "INFO\t2019-02-18 11:52:25 +0100\tmaster-replica-0\t\tglobal_step/sec: 104.807\n",
      "INFO\t2019-02-18 11:52:25 +0100\tmaster-replica-0\t\tloss = 40.41247, step = 901 (0.953 sec)\n",
      "INFO\t2019-02-18 11:52:26 +0100\tmaster-replica-0\t\tglobal_step/sec: 106.735\n",
      "INFO\t2019-02-18 11:52:26 +0100\tmaster-replica-0\t\tloss = 56.066887, step = 1001 (0.937 sec)\n",
      "INFO\t2019-02-18 11:52:27 +0100\tmaster-replica-0\t\tglobal_step/sec: 123.481\n",
      "INFO\t2019-02-18 11:52:27 +0100\tmaster-replica-0\t\tloss = 69.17212, step = 1101 (0.810 sec)\n",
      "INFO\t2019-02-18 11:52:27 +0100\tmaster-replica-0\t\tglobal_step/sec: 119.021\n",
      "INFO\t2019-02-18 11:52:27 +0100\tmaster-replica-0\t\tloss = 44.911655, step = 1201 (0.840 sec)\n",
      "INFO\t2019-02-18 11:52:28 +0100\tmaster-replica-0\t\tglobal_step/sec: 109.615\n",
      "INFO\t2019-02-18 11:52:28 +0100\tmaster-replica-0\t\tloss = 50.094032, step = 1301 (0.913 sec)\n",
      "INFO\t2019-02-18 11:52:29 +0100\tmaster-replica-0\t\tglobal_step/sec: 112.56\n",
      "INFO\t2019-02-18 11:52:29 +0100\tmaster-replica-0\t\tloss = 42.603745, step = 1401 (0.888 sec)\n",
      "INFO\t2019-02-18 11:52:30 +0100\tmaster-replica-0\t\tglobal_step/sec: 104.745\n",
      "INFO\t2019-02-18 11:52:30 +0100\tmaster-replica-0\t\tloss = 49.61542, step = 1501 (0.955 sec)\n",
      "INFO\t2019-02-18 11:52:31 +0100\tmaster-replica-0\t\tglobal_step/sec: 116.735\n",
      "INFO\t2019-02-18 11:52:31 +0100\tmaster-replica-0\t\tloss = 44.09514, step = 1601 (0.856 sec)\n",
      "INFO\t2019-02-18 11:52:32 +0100\tmaster-replica-0\t\tglobal_step/sec: 118.031\n",
      "INFO\t2019-02-18 11:52:32 +0100\tmaster-replica-0\t\tloss = 33.072594, step = 1701 (0.847 sec)\n",
      "INFO\t2019-02-18 11:52:33 +0100\tmaster-replica-0\t\tglobal_step/sec: 110.691\n",
      "INFO\t2019-02-18 11:52:33 +0100\tmaster-replica-0\t\tloss = 48.484806, step = 1801 (0.905 sec)\n",
      "INFO\t2019-02-18 11:52:34 +0100\tmaster-replica-0\t\tglobal_step/sec: 106.028\n",
      "INFO\t2019-02-18 11:52:34 +0100\tmaster-replica-0\t\tloss = 34.51955, step = 1901 (0.942 sec)\n",
      "INFO\t2019-02-18 11:52:35 +0100\tmaster-replica-0\t\tglobal_step/sec: 106.991\n",
      "INFO\t2019-02-18 11:52:35 +0100\tmaster-replica-0\t\tloss = 32.30279, step = 2001 (0.939 sec)\n",
      "INFO\t2019-02-18 11:52:36 +0100\tmaster-replica-0\t\tglobal_step/sec: 122.76\n",
      "INFO\t2019-02-18 11:52:36 +0100\tmaster-replica-0\t\tloss = 46.576942, step = 2101 (0.810 sec)\n",
      "INFO\t2019-02-18 11:52:36 +0100\tmaster-replica-0\t\tglobal_step/sec: 115.519\n",
      "INFO\t2019-02-18 11:52:36 +0100\tmaster-replica-0\t\tloss = 35.051426, step = 2201 (0.866 sec)\n",
      "INFO\t2019-02-18 11:52:37 +0100\tmaster-replica-0\t\tglobal_step/sec: 105.382\n",
      "INFO\t2019-02-18 11:52:37 +0100\tmaster-replica-0\t\tloss = 25.920006, step = 2301 (0.949 sec)\n",
      "INFO\t2019-02-18 11:52:38 +0100\tmaster-replica-0\t\tglobal_step/sec: 104.221\n",
      "INFO\t2019-02-18 11:52:38 +0100\tmaster-replica-0\t\tloss = 23.265404, step = 2401 (0.959 sec)\n",
      "INFO\t2019-02-18 11:52:39 +0100\tmaster-replica-0\t\tglobal_step/sec: 122.531\n",
      "INFO\t2019-02-18 11:52:39 +0100\tmaster-replica-0\t\tloss = 39.81682, step = 2501 (0.817 sec)\n",
      "INFO\t2019-02-18 11:52:40 +0100\tmaster-replica-0\t\tglobal_step/sec: 117.08\n",
      "INFO\t2019-02-18 11:52:40 +0100\tmaster-replica-0\t\tloss = 25.22154, step = 2601 (0.854 sec)\n",
      "INFO\t2019-02-18 11:52:41 +0100\tmaster-replica-0\t\tglobal_step/sec: 113.846\n",
      "INFO\t2019-02-18 11:52:41 +0100\tmaster-replica-0\t\tloss = 35.81294, step = 2701 (0.878 sec)\n",
      "INFO\t2019-02-18 11:52:42 +0100\tmaster-replica-0\t\tglobal_step/sec: 110.905\n",
      "INFO\t2019-02-18 11:52:42 +0100\tmaster-replica-0\t\tloss = 22.22393, step = 2801 (0.902 sec)\n",
      "INFO\t2019-02-18 11:52:43 +0100\tmaster-replica-0\t\tglobal_step/sec: 103.384\n",
      "INFO\t2019-02-18 11:52:43 +0100\tmaster-replica-0\t\tloss = 10.681934, step = 2901 (0.967 sec)\n",
      "INFO\t2019-02-18 11:52:44 +0100\tmaster-replica-0\t\tglobal_step/sec: 123.221\n",
      "INFO\t2019-02-18 11:52:44 +0100\tmaster-replica-0\t\tloss = 32.20569, step = 3001 (0.812 sec)\n",
      "INFO\t2019-02-18 11:52:44 +0100\tmaster-replica-0\t\tglobal_step/sec: 123.252\n",
      "INFO\t2019-02-18 11:52:44 +0100\tmaster-replica-0\t\tloss = 38.779522, step = 3101 (0.811 sec)\n",
      "INFO\t2019-02-18 11:52:45 +0100\tmaster-replica-0\t\tglobal_step/sec: 115.333\n",
      "INFO\t2019-02-18 11:52:45 +0100\tmaster-replica-0\t\tloss = 31.31158, step = 3201 (0.867 sec)\n",
      "INFO\t2019-02-18 11:52:46 +0100\tmaster-replica-0\t\tglobal_step/sec: 114.921\n",
      "INFO\t2019-02-18 11:52:46 +0100\tmaster-replica-0\t\tloss = 30.353138, step = 3301 (0.870 sec)\n",
      "INFO\t2019-02-18 11:52:47 +0100\tmaster-replica-0\t\tglobal_step/sec: 102.897\n",
      "INFO\t2019-02-18 11:52:47 +0100\tmaster-replica-0\t\tloss = 29.302868, step = 3401 (0.972 sec)\n",
      "INFO\t2019-02-18 11:52:48 +0100\tmaster-replica-0\t\tglobal_step/sec: 122.955\n",
      "INFO\t2019-02-18 11:52:48 +0100\tmaster-replica-0\t\tloss = 33.63176, step = 3501 (0.813 sec)\n",
      "INFO\t2019-02-18 11:52:49 +0100\tmaster-replica-0\t\tglobal_step/sec: 120.468\n",
      "INFO\t2019-02-18 11:52:49 +0100\tmaster-replica-0\t\tloss = 33.30413, step = 3601 (0.830 sec)\n",
      "INFO\t2019-02-18 11:52:50 +0100\tmaster-replica-0\t\tglobal_step/sec: 111.124\n",
      "INFO\t2019-02-18 11:52:50 +0100\tmaster-replica-0\t\tloss = 20.989494, step = 3701 (0.900 sec)\n",
      "INFO\t2019-02-18 11:52:51 +0100\tmaster-replica-0\t\tglobal_step/sec: 103.302\n",
      "INFO\t2019-02-18 11:52:51 +0100\tmaster-replica-0\t\tloss = 15.920492, step = 3801 (0.968 sec)\n",
      "INFO\t2019-02-18 11:52:51 +0100\tmaster-replica-0\t\tglobal_step/sec: 114.782\n",
      "INFO\t2019-02-18 11:52:51 +0100\tmaster-replica-0\t\tloss = 13.740409, step = 3901 (0.871 sec)\n",
      "INFO\t2019-02-18 11:52:52 +0100\tmaster-replica-0\t\tglobal_step/sec: 127.275\n",
      "INFO\t2019-02-18 11:52:52 +0100\tmaster-replica-0\t\tloss = 16.958536, step = 4001 (0.786 sec)\n",
      "INFO\t2019-02-18 11:52:53 +0100\tmaster-replica-0\t\tglobal_step/sec: 115.455\n",
      "INFO\t2019-02-18 11:52:53 +0100\tmaster-replica-0\t\tloss = 6.3217974, step = 4101 (0.866 sec)\n",
      "INFO\t2019-02-18 11:52:54 +0100\tmaster-replica-0\t\tglobal_step/sec: 114.527\n",
      "INFO\t2019-02-18 11:52:54 +0100\tmaster-replica-0\t\tloss = 33.860027, step = 4201 (0.873 sec)\n",
      "INFO\t2019-02-18 11:52:55 +0100\tmaster-replica-0\t\tglobal_step/sec: 103.225\n",
      "INFO\t2019-02-18 11:52:55 +0100\tmaster-replica-0\t\tloss = 44.772766, step = 4301 (0.969 sec)\n",
      "INFO\t2019-02-18 11:52:56 +0100\tmaster-replica-0\t\tglobal_step/sec: 128.288\n",
      "INFO\t2019-02-18 11:52:56 +0100\tmaster-replica-0\t\tloss = 20.107887, step = 4401 (0.779 sec)\n",
      "INFO\t2019-02-18 11:52:56 +0100\tmaster-replica-0\t\tglobal_step/sec: 132.392\n",
      "INFO\t2019-02-18 11:52:56 +0100\tmaster-replica-0\t\tloss = 31.663818, step = 4501 (0.755 sec)\n",
      "INFO\t2019-02-18 11:52:57 +0100\tmaster-replica-0\t\tglobal_step/sec: 122.712\n",
      "INFO\t2019-02-18 11:52:57 +0100\tmaster-replica-0\t\tloss = 28.413416, step = 4601 (0.815 sec)\n",
      "INFO\t2019-02-18 11:52:58 +0100\tmaster-replica-0\t\tSaving checkpoints for 4688 into gs://ml-productive-pipeline-53122/pkg_mnist_fnn/trained/model.ckpt.\n",
      "INFO\t2019-02-18 11:53:15 +0100\tmaster-replica-0\t\tCalling model_fn.\n",
      "INFO\t2019-02-18 11:53:15 +0100\tmaster-replica-0\t\tDone calling model_fn.\n",
      "INFO\t2019-02-18 11:53:15 +0100\tmaster-replica-0\t\tStarting evaluation at 2019-02-18-10:53:15\n",
      "INFO\t2019-02-18 11:53:15 +0100\tmaster-replica-0\t\tGraph was finalized.\n",
      "INFO\t2019-02-18 11:53:16 +0100\tmaster-replica-0\t\tRestoring parameters from gs://ml-productive-pipeline-53122/pkg_mnist_fnn/trained/model.ckpt-4688\n",
      "INFO\t2019-02-18 11:53:17 +0100\tmaster-replica-0\t\tRunning local_init_op.\n",
      "INFO\t2019-02-18 11:53:17 +0100\tmaster-replica-0\t\tDone running local_init_op.\n",
      "INFO\t2019-02-18 11:53:18 +0100\tmaster-replica-0\t\tFinished evaluation at 2019-02-18-10:53:18\n",
      "INFO\t2019-02-18 11:53:18 +0100\tmaster-replica-0\t\tSaving dict for global step 4688: accuracy = 0.9641, average_loss = 0.12913208, global_step = 4688, loss = 16.345833\n",
      "INFO\t2019-02-18 11:53:22 +0100\tmaster-replica-0\t\tSaving 'checkpoint_path' summary for global step 4688: gs://ml-productive-pipeline-53122/pkg_mnist_fnn/trained/model.ckpt-4688\n",
      "INFO\t2019-02-18 11:53:27 +0100\tmaster-replica-0\t\tCalling model_fn.\n",
      "INFO\t2019-02-18 11:53:27 +0100\tmaster-replica-0\t\tDone calling model_fn.\n",
      "INFO\t2019-02-18 11:53:27 +0100\tmaster-replica-0\t\tSignatures INCLUDED in export for Train: None\n",
      "INFO\t2019-02-18 11:53:27 +0100\tmaster-replica-0\t\tSignatures INCLUDED in export for Regress: None\n",
      "INFO\t2019-02-18 11:53:27 +0100\tmaster-replica-0\t\tSignatures INCLUDED in export for Eval: None\n",
      "INFO\t2019-02-18 11:53:27 +0100\tmaster-replica-0\t\tSignatures INCLUDED in export for Predict: ['predict']\n",
      "INFO\t2019-02-18 11:53:27 +0100\tmaster-replica-0\t\tSignatures INCLUDED in export for Classify: None\n",
      "INFO\t2019-02-18 11:53:27 +0100\tmaster-replica-0\t\tSignatures EXCLUDED from export because they cannot be be served via TensorFlow Serving APIs:\n",
      "INFO\t2019-02-18 11:53:27 +0100\tmaster-replica-0\t\t'classification' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "INFO\t2019-02-18 11:53:27 +0100\tmaster-replica-0\t\t'serving_default' : Classification input must be a single string Tensor; got {'x': <tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>}\n",
      "WARNING\t2019-02-18 11:53:27 +0100\tmaster-replica-0\t\tExport includes no default signature!\n",
      "INFO\t2019-02-18 11:53:27 +0100\tmaster-replica-0\t\tRestoring parameters from gs://ml-productive-pipeline-53122/pkg_mnist_fnn/trained/model.ckpt-4688\n",
      "WARNING\t2019-02-18 11:53:28 +0100\tmaster-replica-0\t\tFrom /usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py:1044: calling SavedModelBuilder.add_meta_graph_and_variables (from tensorflow.python.saved_model.builder_impl) with legacy_init_op is deprecated and will be removed in a future version.\n",
      "WARNING\t2019-02-18 11:53:28 +0100\tmaster-replica-0\t\tInstructions for updating:\n",
      "WARNING\t2019-02-18 11:53:28 +0100\tmaster-replica-0\t\tPass your op to the equivalent parameter main_op instead.\n",
      "INFO\t2019-02-18 11:53:28 +0100\tmaster-replica-0\t\tAssets added to graph.\n",
      "INFO\t2019-02-18 11:53:28 +0100\tmaster-replica-0\t\tNo assets to write.\n",
      "INFO\t2019-02-18 11:53:42 +0100\tmaster-replica-0\t\tSavedModel written to: gs://ml-productive-pipeline-53122/pkg_mnist_fnn/trained/export/exporter/temp-b'1550487203'/saved_model.pb\n",
      "INFO\t2019-02-18 11:53:48 +0100\tmaster-replica-0\t\tLoss for final step: 11.554545.\n",
      "INFO\t2019-02-18 11:53:49 +0100\tmaster-replica-0\t\t['dnn/head/beta1_power', 'dnn/head/beta2_power', 'dnn/hiddenlayer_0/bias', 'dnn/hiddenlayer_0/bias/t_0/Adam', 'dnn/hiddenlayer_0/bias/t_0/Adam_1', 'dnn/hiddenlayer_0/kernel', 'dnn/hiddenlayer_0/kernel/t_0/Adam', 'dnn/hiddenlayer_0/kernel/t_0/Adam_1', 'dnn/hiddenlayer_1/bias', 'dnn/hiddenlayer_1/bias/t_0/Adam', 'dnn/hiddenlayer_1/bias/t_0/Adam_1', 'dnn/hiddenlayer_1/kernel', 'dnn/hiddenlayer_1/kernel/t_0/Adam', 'dnn/hiddenlayer_1/kernel/t_0/Adam_1', 'dnn/hiddenlayer_2/bias', 'dnn/hiddenlayer_2/bias/t_0/Adam', 'dnn/hiddenlayer_2/bias/t_0/Adam_1', 'dnn/hiddenlayer_2/kernel', 'dnn/hiddenlayer_2/kernel/t_0/Adam', 'dnn/hiddenlayer_2/kernel/t_0/Adam_1', 'dnn/logits/bias', 'dnn/logits/bias/t_0/Adam', 'dnn/logits/bias/t_0/Adam_1', 'dnn/logits/kernel', 'dnn/logits/kernel/t_0/Adam', 'dnn/logits/kernel/t_0/Adam_1', 'global_step']\n",
      "INFO\t2019-02-18 11:53:49 +0100\tmaster-replica-0\t\tModule completed; cleaning up.\n",
      "INFO\t2019-02-18 11:53:49 +0100\tmaster-replica-0\t\tClean up finished.\n",
      "INFO\t2019-02-18 11:53:49 +0100\tmaster-replica-0\t\tTask completed successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "View job in the Cloud Console at:\n",
      "https://console.cloud.google.com/ml/jobs/mnist_190218_105007?project=ml-productive-pipeline-53122\n",
      "\n",
      "View logs at:\n",
      "https://console.cloud.google.com/logs?resource=ml.googleapis.com%2Fjob_id%2Fmnist_190218_105007&project=ml-productive-pipeline-53122\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud ml-engine jobs describe    mnist_190218_105007\n",
    "gcloud ml-engine jobs stream-logs mnist_190218_105007"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't be concerned if the notebook appears stalled (with a blue progress bar) or returns with an error about being unable to refresh auth tokens. This is a long-lived Cloud job and work is going on in the cloud. \n",
    "\n",
    "<b>Use the Cloud Console link to monitor the job and do NOT proceed until the job is done.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check Results using TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://ml-productive-pipeline-53122/pkg_mnist_fnn/trained\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "#gcloud auth application-default login\n",
    "echo $OUTDIR\n",
    "#tensorboard --logdir $OUTDIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Deploy model </h2>\n",
    "\n",
    "Find out the actual name of the subdirectory where the model is stored and use it to deploy the model.  Deploying model will take up to <b>5 minutes</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "gsutil ls gs://${BUCKET}/$PKG_NAME/trained/export/exporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "MODEL_NAME=\"MNIST_MLENGINE\"\n",
    "MODEL_VERSION=\"v1\"\n",
    "MODEL_LOCATION=$(gsutil ls gs://${BUCKET}/$PKG_NAME/trained/export/exporter | tail -1)\n",
    "echo \"Run these commands one-by-one (the very first time, you'll create a model and then create a version)\"\n",
    "#gcloud ml-engine versions delete ${MODEL_VERSION} --model ${MODEL_NAME}\n",
    "#gcloud ml-engine models delete ${MODEL_NAME}\n",
    "gcloud ml-engine models   create ${MODEL_NAME} --regions $REGION\n",
    "gcloud ml-engine versions create ${MODEL_VERSION} --model ${MODEL_NAME} --origin ${MODEL_LOCATION} --runtime-version $TFVERSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Prediction </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASS_IDS  CLASSES  LOGITS                                                                                                                                                                                                       PROBABILITIES\n",
      "[8]        [u'8']   [-1.3327929973602295, 2.2530980110168457, 3.4556188583374023, 5.9954352378845215, 0.09868371486663818, 3.893829345703125, 3.669095754623413, 2.418844699859619, 11.398612022399902, 4.405415058135986]       [2.9361999622778967e-06, 0.00010595430649118498, 0.00035266843042336404, 0.004470898769795895, 1.2287626304896548e-05, 0.0005466117872856557, 0.0004365947679616511, 0.00012505512859206647, 0.9930353164672852, 0.0009117123554460704]\n",
      "[5]        [u'5']   [-15.63167953491211, 0.5527050495147705, -10.781968116760254, 31.3237247467041, -1.7304039001464844, 47.42430114746094, 9.034704208374023, -9.172748565673828, 25.79246711730957, 28.165958404541016]        [4.122260934448926e-28, 4.404776747626436e-21, 5.264277745420179e-26, 1.0176734832612055e-07, 4.491410992094295e-22, 0.9999998807907104, 2.1262320303650953e-17, 2.631561833283872e-25, 4.031009137595021e-10, 4.3272101457603185e-09]\n",
      "[3]        [u'3']   [1.9985772371292114, 9.424895286560059, 13.256902694702148, 19.65593910217285, -5.417698860168457, 9.951102256774902, 1.3079330921173096, 3.521822452545166, 13.247543334960938, 8.244338989257812]          [2.1380740733434322e-08, 3.5911354643758386e-05, 0.0016574920155107975, 0.9965925812721252, 1.2858035816631919e-11, 6.077998114051297e-05, 1.0717172038710032e-08, 9.807529011141014e-08, 0.0016420513857156038, 1.1028658263967372e-05]\n",
      "[6]        [u'6']   [0.008612308651208878, -8.488609313964844, -4.6168413162231445, -8.664852142333984, 7.087252616882324, 5.371450424194336, 29.441234588623047, -13.30738353729248, -0.7796090841293335, -18.816394805908203]  [1.6503432734987777e-13, 3.367271286585349e-17, 1.617208348336232e-15, 2.8231684232602185e-17, 1.957894957271833e-10, 3.5206719484204285e-11, 1.0, 2.7196349202369323e-19, 7.503330910155898e-14, 1.1014830740809882e-21]\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud ml-engine predict --model=MNIST_MLENGINE --version=v1 --json-instances=data/test.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "with open(\"data/test.json\", \"r\") as f:\n",
    "    images = f.readlines()\n",
    "plt.figure(figsize=(20,4))\n",
    "for i, image in enumerate(images):\n",
    "    if i < 4:\n",
    "        image = json.loads(image)\n",
    "        image = np.array(image['x'])\n",
    "        plt.subplot(1, 5, i+1)\n",
    "        plt.imshow(np.reshape(image, (28,28)), cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunatly, we do not have a True Positve. ToDO: Add more examples!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get predictions using the [Python-Client-Library, see Tutorial](https://cloud.google.com/ml-engine/docs/tensorflow/python-client-library). Since we have created and deployed a model already, we use the [`predict`](https://cloud.google.com/ml-engine/reference/rest/v1/projects) Method instead of `create` as in the documentation. \n",
    "\n",
    "[API-Reference](https://cloud.google.com/ml-engine/reference/rest/)\n",
    "\n",
    "If you need a service account authentification, please follow [this link]() and uncomment the celllines after this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %bash\n",
    "# export GOOGLE_APPLICATION_CREDENTIALS=$PWD/ML-productive-pipeline-53122-64d3c31786e7.json\n",
    "# echo $GOOGLE_APPLICATION_CREDENTIALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/content/datalab/proj_DL_models_and_pipelines_with_GCP/notebook/../ML-productive-pipeline-53122-64d3c31786e7.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from oauth2client.client import GoogleCredentials\n",
    "from googleapiclient import discovery\n",
    "from googleapiclient import errors\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pdoc discovery.build"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Signature: discovery.build(serviceName, version, http=None, discoveryServiceUrl='https://www.googleapis.com/discovery/v1/apis/{api}/{apiVersion}/rest', developerKey=None, model=None, requestBuilder=<class 'googleapiclient.http.HttpRequest'>, credentials=None, cache_discovery=True, cache=None)\n",
    "Docstring:\n",
    "Construct a Resource for interacting with an API.\n",
    "\n",
    "Construct a Resource object for interacting with an API. The serviceName and\n",
    "version are the names from the Discovery service.\n",
    "\n",
    "Args:\n",
    "serviceName: string, name of the service.\n",
    "version: string, the version of the service.\n",
    "http: httplib2.Http, An instance of httplib2.Http or something that acts\n",
    "like it that HTTP requests will be made through.\n",
    "discoveryServiceUrl: string, a URI Template that points to the location of\n",
    "the discovery service. It should have two parameters {api} and\n",
    "{apiVersion} that when filled in produce an absolute URI to the discovery\n",
    "document for that service.\n",
    "developerKey: string, key obtained from\n",
    "https://code.google.com/apis/console.\n",
    "model: googleapiclient.Model, converts to and from the wire format.\n",
    "requestBuilder: googleapiclient.http.HttpRequest, encapsulator for an HTTP\n",
    "request.\n",
    "credentials: oauth2client.Credentials or\n",
    "google.auth.credentials.Credentials, credentials to be used for\n",
    "authentication.\n",
    "cache_discovery: Boolean, whether or not to cache the discovery doc.\n",
    "cache: googleapiclient.discovery_cache.base.CacheBase, an optional\n",
    "cache object for the discovery documents.\n",
    "\n",
    "Returns:\n",
    "A Resource object with methods for interacting with the service.\n",
    "File: /usr/local/envs/py3env/lib/python3.5/site-packages/googleapiclient/discovery.py\n",
    "Type: function\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/enryh/miniconda3/envs/gcp_dl/lib/python3.6/site-packages/google/auth/_default.py:66: UserWarning: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a \"quota exceeded\" or \"API not enabled\" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/\n",
      "  warnings.warn(_CLOUD_SDK_CREDENTIALS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "api = discovery.build(serviceName='ml', version='v1',\n",
    "                      http=None, \n",
    "                      discoveryServiceUrl='https://www.googleapis.com/discovery/v1/apis/{api}/{apiVersion}/rest', \n",
    "                      developerKey=None, \n",
    "                      model=None, \n",
    "                      #requestBuilder=<class 'googleapiclient.http.HttpRequest'>, \n",
    "                      credentials=None, \n",
    "                      cache_discovery=True, \n",
    "                      cache=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<googleapiclient.discovery.Resource at 0x7f63c019eb00>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'MNIST_MLENGINE'\n",
    "VERSION = 'v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data from /home/enryh/proj_DL_models_and_pipelines_with_GCP/data/mnist.npz\n"
     ]
    }
   ],
   "source": [
    "from src.pkg_mnist_fnn.utils import load_data\n",
    "from src.pkg_mnist_fnn.model import parse_images\n",
    "(_,_), (x_test, y_test) = load_data(rel_path='data')\n",
    "N=4\n",
    "test_indices = np.random.randint(low=0, high=len(y_test), size=N)\n",
    "x_test, y_test = x_test[test_indices], y_test[test_indices]\n",
    "x_test = parse_images(x_test).tolist()\n",
    "\n",
    "eol = \"\\r\\n\"\n",
    "n_lines = len(y_test)\n",
    "instances = []\n",
    "with open(\"data/test.json\", \"r\") as f:\n",
    "    for image, label in zip(x_test, y_test):\n",
    "        instances.append({\"x\": image}) #, \"y\": int(label)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predictions': [{'probabilities': [5.713608335540272e-16, 1.0, 1.3980798940424477e-12, 4.7910243176428484e-18, 5.213703600792652e-12, 2.4374503316831485e-16, 4.583709178092025e-19, 1.8915770283456368e-08, 7.380032140957837e-10, 4.496945562576364e-16], 'class_ids': [1], 'classes': ['1'], 'logits': [-2.9880850315093994, 32.11042404174805, 4.8145036697387695, -7.769362449645996, 6.1306939125061035, -3.839984893798828, -10.116183280944824, 14.327154159545898, 11.083351135253906, -3.227539539337158]}, {'probabilities': [7.197160556415838e-08, 7.433108635268582e-07, 6.9033926592965145e-06, 7.828126032593738e-14, 0.9998289346694946, 9.057208108509407e-14, 2.4880728233256377e-07, 0.00015889573842287064, 2.965273138144653e-09, 4.127837200940121e-06], 'class_ids': [4], 'classes': ['4'], 'logits': [10.880867958068848, 13.215709686279297, 15.444363594055176, -2.8506062030792236, 27.32769012451172, -2.704768657684326, 12.1212739944458, 18.580598831176758, 7.691564083099365, 14.93010425567627]}, {'probabilities': [1.8343232003324196e-14, 2.6027384691929e-09, 2.0887836545049193e-13, 6.130331894382834e-05, 1.7005855057483643e-11, 0.9997416138648987, 5.3448398830369115e-05, 9.904187904446267e-16, 0.0001394685823470354, 4.259410616214154e-06], 'class_ids': [5], 'classes': ['5'], 'logits': [-12.403220176696777, -0.5404055118560791, -9.970728874206543, 9.526619911193848, -5.5711669921875, 19.226037979125977, 9.38950252532959, -15.322107315063477, 10.348625183105469, 6.859917163848877]}, {'probabilities': [1.0, 2.528652504568123e-34, 1.037414123887096e-16, 1.2942465944674462e-19, 2.79763592987228e-29, 2.510007609743403e-12, 4.240445478477864e-14, 9.64603968774873e-24, 5.823471453562135e-18, 4.275215630391237e-16], 'class_ids': [0], 'classes': ['0'], 'logits': [68.6109848022461, -8.749218940734863, 31.806354522705078, 25.119794845581055, 2.8647894859313965, 41.90024948120117, 37.819461822509766, 15.615490913391113, 28.926349639892578, 33.22245788574219]}]}\n"
     ]
    }
   ],
   "source": [
    "project_id = 'projects/{}/models/{}/versions/{}'.format(PROJECT, MODEL_NAME, VERSION)\n",
    "request_data = {\"instances\":\n",
    "    instances\n",
    "}\n",
    "request = api.projects().predict(body=request_data, name=project_id).execute()\n",
    "print(request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 1, True Class:\t1\n",
      "Predicted class: 4, True Class:\t4\n",
      "Predicted class: 5, True Class:\t5\n",
      "Predicted class: 0, True Class:\t0\n"
     ]
    }
   ],
   "source": [
    "for i, pred in enumerate(request['predictions']):\n",
    "    print(\"Predicted class: {}, True Class:\\t{}\".format(pred['classes'][0], y_test[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 4, 5, 0], dtype=uint8)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predictions': [{'probabilities': [0.07440567761659622, 0.06085335463285446, 0.0796218290925026, 0.09449440240859985, 0.0755155086517334, 0.08171500265598297, 0.06408874690532684, 0.07522281259298325, 0.28817883133888245, 0.10590385645627975], 'class_ids': [8], 'classes': ['8'], 'logits': [-0.11568695306777954, -0.31675225496292114, -0.047930844128131866, 0.12332145869731903, -0.10088106244802475, -0.021981418132781982, -0.2649504244327545, -0.10476464033126831, 1.2383620738983154, 0.23731258511543274]}]}\n"
     ]
    }
   ],
   "source": [
    "project_id = 'projects/{}/models/{}/versions/{}'.format(PROJECT, MODEL_NAME, VERSION)\n",
    "request_data = {\"instances\":\n",
    "  [\n",
    "   {\"x\": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3294117748737335, 0.7254902124404907, 0.6235294342041016, 0.5921568870544434, 0.23529411852359772, 0.1411764770746231, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8705882430076599, 0.9960784316062927, 0.9960784316062927, 0.9960784316062927, 0.9960784316062927, 0.9450980424880981, 0.7764706015586853, 0.7764706015586853, 0.7764706015586853, 0.7764706015586853, 0.7764706015586853, 0.7764706015586853, 0.7764706015586853, 0.7764706015586853, 0.6666666865348816, 0.20392157137393951, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.26274511218070984, 0.4470588266849518, 0.2823529541492462, 0.4470588266849518, 0.6392157077789307, 0.8901960849761963, 0.9960784316062927, 0.8823529481887817, 0.9960784316062927, 0.9960784316062927, 0.9960784316062927, 0.9803921580314636, 0.8980392217636108, 0.9960784316062927, 0.9960784316062927, 0.5490196347236633, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06666667014360428, 0.25882354378700256, 0.054901961237192154, 0.26274511218070984, 0.26274511218070984, 0.26274511218070984, 0.23137255012989044, 0.08235294371843338, 0.9254902005195618, 0.9960784316062927, 0.4156862795352936, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.32549020648002625, 0.9921568632125854, 0.8196078538894653, 0.07058823853731155, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08627451211214066, 0.9137254953384399, 1.0, 0.32549020648002625, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5058823823928833, 0.9960784316062927, 0.9333333373069763, 0.1725490242242813, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.23137255012989044, 0.9764705896377563, 0.9960784316062927, 0.24313725531101227, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5215686559677124, 0.9960784316062927, 0.7333333492279053, 0.019607843831181526, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.03529411926865578, 0.8039215803146362, 0.9725490212440491, 0.22745098173618317, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4941176474094391, 0.9960784316062927, 0.7137255072593689, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.29411765933036804, 0.9843137264251709, 0.9411764740943909, 0.2235294133424759, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07450980693101883, 0.8666666746139526, 0.9960784316062927, 0.6509804129600525, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0117647061124444, 0.7960784435272217, 0.9960784316062927, 0.8588235378265381, 0.13725490868091583, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14901961386203766, 0.9960784316062927, 0.9960784316062927, 0.3019607961177826, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.12156862765550613, 0.8784313797950745, 0.9960784316062927, 0.45098039507865906, 0.003921568859368563, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5215686559677124, 0.9960784316062927, 0.9960784316062927, 0.20392157137393951, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.239215686917305, 0.9490196108818054, 0.9960784316062927, 0.9960784316062927, 0.20392157137393951, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4745098054409027, 0.9960784316062927, 0.9960784316062927, 0.8588235378265381, 0.1568627506494522, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4745098054409027, 0.9960784316062927, 0.8117647171020508, 0.07058823853731155, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}\n",
    "  ]\n",
    "}\n",
    "request = api.projects().predict(body=request_data, name=project_id).execute()\n",
    "print(request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
