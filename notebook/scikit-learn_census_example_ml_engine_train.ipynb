{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Copyright 2019 Google LLC\n",
    "\n",
    "- Adapted to own project, source: [github.com/GoogleCloudPlatform/cloudml-samples/](https://github.com/GoogleCloudPlatform/cloudml-samples/blob/master/notebooks/scikit-learn/Training%20with%20scikit-learn%20in%20CMLE.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scikit-learn Training on Google Cloud Machine Learning Engine\n",
    "This notebook uses the [Census Income Data Set](https://archive.ics.uci.edu/ml/datasets/Census+Income) to demonstrate how to train a model on Cloud Machine Learning Engine (ML Engine)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to bring your model to ML Engine\n",
    "Getting your model ready for training can be done in 3 steps:\n",
    "1. Create your python model file\n",
    "    1. Add code to download your data from [Google Cloud Storage](https://cloud.google.com/storage) so that ML Engine can use it\n",
    "    1. Add code to export and save the model to [Google Cloud Storage](https://cloud.google.com/storage) once ML Engine finishes training the model\n",
    "1. Prepare a package\n",
    "1. Submit the training job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prerequisites\n",
    "Before you jump in, let’s cover some of the different tools you’ll be using to get online prediction up and running on ML Engine. \n",
    "\n",
    "[Google Cloud Platform](https://cloud.google.com/) lets you build and host applications and websites, store data, and analyze data on Google's scalable infrastructure.\n",
    "\n",
    "[Cloud ML Engine](https://cloud.google.com/ml-engine/) is a managed service that enables you to easily build machine learning models that work on any type of data, of any size.\n",
    "\n",
    "[Google Cloud Storage](https://cloud.google.com/storage/) (GCS) is a unified object storage for developers and enterprises, from live data serving to data analytics/ML to data archiving.\n",
    "\n",
    "[Cloud SDK](https://cloud.google.com/sdk/) is a command line tool which allows you to interact with Google Cloud products. In order to run this notebook, make sure that Cloud SDK is [installed](https://cloud.google.com/sdk/downloads) in the same environment as your Jupyter kernel.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 0: Setup\n",
    "* [Create a project on GCP](https://cloud.google.com/resource-manager/docs/creating-managing-projects)\n",
    "* [Create a Google Cloud Storage Bucket](https://cloud.google.com/storage/docs/quickstart-console)\n",
    "* [Enable Cloud Machine Learning Engine and Compute Engine APIs](https://console.cloud.google.com/flows/enableapi?apiid=ml.googleapis.com,compute_component&_ga=2.217405014.1312742076.1516128282-1417583630.1516128282)\n",
    "* [Install Cloud SDK](https://cloud.google.com/sdk/downloads)\n",
    "* [Install scikit-learn](http://scikit-learn.org/stable/install.html) [Optional: used if running locally]\n",
    "* [Install pandas](https://pandas.pydata.org/pandas-docs/stable/install.html) [Optional: used if running locally]\n",
    "\n",
    "These variables will be needed for the following steps.\n",
    "* `TRAINER_PACKAGE_PATH <./census_training>` - A packaged training application that will be staged in a Google Cloud Storage location. The model file created below is placed inside this package path.\n",
    "* `MAIN_TRAINER_MODULE <census_training.train>` - Tells ML Engine which file to execute. This is formatted as follows <folder_name.python_file_name>\n",
    "* `JOB_DIR <gs://$BUCKET_NAME/scikit_learn_job_dir>` - The path to a Google Cloud Storage location to use for job output.\n",
    "* `RUNTIME_VERSION <1.9>` - The version of Cloud ML Engine to use for the job. If you don't specify a runtime version, the training service uses the default Cloud ML Engine runtime version 1.0. [See the list of runtime versions for more information](https://cloud.google.com/ml-engine/docs/tensorflow/runtime-version-list).\n",
    "* `PYTHON_VERSION <3.5>` - The Python version to use for the job. Python 3.5 is available with runtime version 1.4 or greater. If you don't specify a Python version, the training service uses Python 2.7.\n",
    "\n",
    "** Replace: **\n",
    "* `PROJECT_ID <YOUR_PROJECT_ID>` - with your project's id. Use the PROJECT_ID that matches your Google Cloud Platform project.\n",
    "* `BUCKET_NAME <YOUR_BUCKET_NAME>` - with the bucket id you created above.\n",
    "* `JOB_DIR <gs://YOUR_BUCKET_NAME/scikit_learn_job_dir>` - with the bucket id you created above.\n",
    "* `REGION <REGION>` - select a region from [here](https://cloud.google.com/ml-engine/docs/regions) or use the default '`us-central1`'. The region is where the model will be deployed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working direcotory:\t/home/enryh/gcp_poc/project\n"
     ]
    }
   ],
   "source": [
    "from utils import chdir_\n",
    "pwd = chdir_()\n",
    "\n",
    "import yaml\n",
    "with open('config.yaml', 'r') as f:\n",
    "    #cfg = yaml.load(f, Loader=yaml.BaseLoader)\n",
    "    cfg = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PROJECT_ID=ml-productive-pipeline-53122\n",
      "env: BUCKET_NAME=ml-productive-pipeline-53122\n",
      "env: REGION=europe-west1\n",
      "env: TRAINER_PACKAGE_PATH=src/census_training\n",
      "env: MAIN_TRAINER_MODULE=census_training.train\n",
      "env: JOB_DIR=gs://ml-productive-pipeline-53122/scikit_learn_job_dir\n",
      "env: RUNTIME_VERSION=1.13\n",
      "env: PYTHON_VERSION=3.5\n",
      "mkdir: cannot create directory ‘src/census_training’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "pkg_dir = os.path.normpath('src/census_training')\n",
    "%env PROJECT_ID {cfg['project-id']}\n",
    "%env BUCKET_NAME {cfg['bucket']}\n",
    "%env REGION {cfg['region']}\n",
    "%env TRAINER_PACKAGE_PATH $pkg_dir\n",
    "%env MAIN_TRAINER_MODULE census_training.train\n",
    "%env JOB_DIR gs://{cfg['bucket']}/scikit_learn_job_dir\n",
    "%env RUNTIME_VERSION 1.13\n",
    "%env PYTHON_VERSION 3.5\n",
    "!mkdir $pkg_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  The data\n",
    "The [Census Income Data Set](https://archive.ics.uci.edu/ml/datasets/Census+Income) that this sample\n",
    "uses for training is provided by the [UC Irvine Machine Learning\n",
    "Repository](https://archive.ics.uci.edu/ml/datasets/). We have hosted the data on a public GCS bucket `gs://cloud-samples-data/ml-engine/sklearn/census_data/`. \n",
    "\n",
    " * Training file is `adult.data`\n",
    " * Evaluation file is `adult.test` (not used in this notebook)\n",
    "\n",
    "Note: Your typical development process with your own data would require you to upload your data to GCS so that ML Engine can access that data. However, in this case, we have put the data on GCS to avoid the steps of having you download the data from UC Irvine and then upload the data to GCS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disclaimer\n",
    "This dataset is provided by a third party. Google provides no representation,\n",
    "warranty, or other guarantees about the validity or any other aspects of this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Create your python model file\n",
    "\n",
    "First, we'll create the python model file (provided below) that we'll upload to ML Engine. This is similar to your normal process for creating a scikit-learn model. However, there are two key differences:\n",
    "1. Downloading the data from GCS at the start of your file, so that ML Engine can access the data.\n",
    "1. Exporting/saving the model to GCS at the end of your file, so that you can use it for predictions.\n",
    "\n",
    "The code in this file loads the data into a pandas DataFrame that can be used by scikit-learn. Then the model is fit against the training data. Lastly, sklearn's built in version of joblib is used to save the model to a file that can be uploaded to [ML Engine's prediction service](https://cloud.google.com/ml-engine/docs/scikit/getting-predictions#deploy_models_and_versions).\n",
    "\n",
    "**REPLACE Line 18: BUCKET_NAME = '<BUCKET_NAME>' with your GCS BUCKET_NAME**\n",
    "\n",
    "Note: In normal practice you would want to test your model locally on a small dataset to ensure that it works, before using it with your larger dataset on ML Engine. This avoids wasted time and costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/census_training/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $pkg_dir/train.py\n",
    "# [START setup]\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "from google.cloud import storage\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "\n",
    "# TODO: REPLACE '<BUCKET_NAME>' with your GCS BUCKET_NAME\n",
    "BUCKET_NAME = 'ml-productive-pipeline-53122'\n",
    "# [END setup]\n",
    "\n",
    "\n",
    "# ---------------------------------------\n",
    "# 1. Add code to download the data from GCS (in this case, using the publicly hosted data).\n",
    "# ML Engine will then be able to use the data when training your model.\n",
    "# ---------------------------------------\n",
    "# [START download-data]\n",
    "# Public bucket holding the census data\n",
    "bucket = storage.Client().bucket('cloud-samples-data')\n",
    "\n",
    "# Path to the data inside the public bucket\n",
    "blob = bucket.blob('ml-engine/sklearn/census_data/adult.data')\n",
    "# Download the data\n",
    "blob.download_to_filename('adult.data')\n",
    "# [END download-data]\n",
    "\n",
    "\n",
    "# ---------------------------------------\n",
    "# This is where your model code would go. Below is an example model using the census dataset.\n",
    "# ---------------------------------------\n",
    "# [START define-and-load-data]\n",
    "# Define the format of your input data including unused columns (These are the columns from the census data files)\n",
    "COLUMNS = (\n",
    "    'age',\n",
    "    'workclass',\n",
    "    'fnlwgt',\n",
    "    'education',\n",
    "    'education-num',\n",
    "    'marital-status',\n",
    "    'occupation',\n",
    "    'relationship',\n",
    "    'race',\n",
    "    'sex',\n",
    "    'capital-gain',\n",
    "    'capital-loss',\n",
    "    'hours-per-week',\n",
    "    'native-country',\n",
    "    'income-level'\n",
    ")\n",
    "\n",
    "# Categorical columns are columns that need to be turned into a numerical value to be used by scikit-learn\n",
    "CATEGORICAL_COLUMNS = (\n",
    "    'workclass',\n",
    "    'education',\n",
    "    'marital-status',\n",
    "    'occupation',\n",
    "    'relationship',\n",
    "    'race',\n",
    "    'sex',\n",
    "    'native-country'\n",
    ")\n",
    "\n",
    "\n",
    "# Load the training census dataset\n",
    "with open('./adult.data', 'r') as train_data:\n",
    "    raw_training_data = pd.read_csv(train_data, header=None, names=COLUMNS)\n",
    "\n",
    "# Remove the column we are trying to predict ('income-level') from our features list\n",
    "# Convert the Dataframe to a lists of lists\n",
    "train_features = raw_training_data.drop('income-level', axis=1).values.tolist()\n",
    "# Create our training labels list, convert the Dataframe to a lists of lists\n",
    "train_labels = (raw_training_data['income-level'] == ' >50K').values.tolist()\n",
    "# [END define-and-load-data]\n",
    "\n",
    "\n",
    "# [START categorical-feature-conversion]\n",
    "# Since the census data set has categorical features, we need to convert\n",
    "# them to numerical values. We'll use a list of pipelines to convert each\n",
    "# categorical column and then use FeatureUnion to combine them before calling\n",
    "# the RandomForestClassifier.\n",
    "categorical_pipelines = []\n",
    "\n",
    "# Each categorical column needs to be extracted individually and converted to a numerical value.\n",
    "# To do this, each categorical column will use a pipeline that extracts one feature column via\n",
    "# SelectKBest(k=1) and a LabelBinarizer() to convert the categorical value to a numerical one.\n",
    "# A scores array (created below) will select and extract the feature column. The scores array is\n",
    "# created by iterating over the COLUMNS and checking if it is a CATEGORICAL_COLUMN.\n",
    "for i, col in enumerate(COLUMNS[:-1]):\n",
    "    if col in CATEGORICAL_COLUMNS:\n",
    "        # Create a scores array to get the individual categorical column.\n",
    "        # Example:\n",
    "        #  data = [39, 'State-gov', 77516, 'Bachelors', 13, 'Never-married', 'Adm-clerical', \n",
    "        #         'Not-in-family', 'White', 'Male', 2174, 0, 40, 'United-States']\n",
    "        #  scores = [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "        #\n",
    "        # Returns: [['State-gov']]\n",
    "        # Build the scores array\n",
    "        scores = [0] * len(COLUMNS[:-1])\n",
    "        # This column is the categorical column we want to extract.\n",
    "        scores[i] = 1\n",
    "        skb = SelectKBest(k=1)\n",
    "        skb.scores_ = scores\n",
    "        # Convert the categorical column to a numerical value\n",
    "        lbn = LabelBinarizer()\n",
    "        r = skb.transform(train_features)\n",
    "        lbn.fit(r)\n",
    "        # Create the pipeline to extract the categorical feature\n",
    "        categorical_pipelines.append(\n",
    "            ('categorical-{}'.format(i), Pipeline([\n",
    "                ('SKB-{}'.format(i), skb),\n",
    "                ('LBN-{}'.format(i), lbn)])))\n",
    "# [END categorical-feature-conversion]\n",
    "\n",
    "# [START create-pipeline]\n",
    "# Create pipeline to extract the numerical features\n",
    "skb = SelectKBest(k=6)\n",
    "# From COLUMNS use the features that are numerical\n",
    "skb.scores_ = [1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0]\n",
    "categorical_pipelines.append(('numerical', skb))\n",
    "\n",
    "# Combine all the features using FeatureUnion\n",
    "preprocess = FeatureUnion(categorical_pipelines)\n",
    "\n",
    "# Create the classifier\n",
    "classifier = RandomForestClassifier()\n",
    "\n",
    "# Transform the features and fit them to the classifier\n",
    "classifier.fit(preprocess.transform(train_features), train_labels)\n",
    "\n",
    "# Create the overall model as a single pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('union', preprocess),\n",
    "    ('classifier', classifier)\n",
    "])\n",
    "# [END create-pipeline]\n",
    "\n",
    "\n",
    "# ---------------------------------------\n",
    "# 2. Export and save the model to GCS\n",
    "# ---------------------------------------\n",
    "# [START export-to-gcs]\n",
    "# Export the model to a file\n",
    "model = 'model.joblib'\n",
    "joblib.dump(pipeline, model)\n",
    "\n",
    "# Upload the model to GCS\n",
    "bucket = storage.Client().bucket(BUCKET_NAME)\n",
    "blob = bucket.blob('scikit_learn/{}/{}'.format(\n",
    "    datetime.datetime.now().strftime('census_%Y%m%d_%H%M%S'),\n",
    "    model))\n",
    "blob.upload_from_filename(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Create Trainer Package\n",
    "Before you can run your trainer application with ML Engine, your code and any dependencies must be placed in a Google Cloud Storage location that your Google Cloud Platform project can access. You can find more info [here](https://cloud.google.com/ml-engine/docs/tensorflow/packaging-trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/census_training/__init__.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $pkg_dir/__init__.py\n",
    "# Note that __init__.py can be an empty file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Submit Training Job\n",
    "Next we need to submit the job for training on ML Engine. We'll use gcloud to submit the job which has the following flags:\n",
    "\n",
    "* `job-name` - A name to use for the job (mixed-case letters, numbers, and underscores only, starting with a letter). In this case: `census_training_$(date +\"%Y%m%d_%H%M%S\")`\n",
    "* `job-dir` - The path to a Google Cloud Storage location to use for job output.\n",
    "* `package-path` - A packaged training application that is staged in a Google Cloud Storage location. If you are using the gcloud command-line tool, this step is largely automated.\n",
    "* `module-name` - The name of the main module in your trainer package. The main module is the Python file you call to start the application. If you use the gcloud command to submit your job, specify the main module name in the --module-name argument. Refer to Python Packages to figure out the module name.\n",
    "* `region` - The Google Cloud Compute region where you want your job to run. You should run your training job in the same region as the Cloud Storage bucket that stores your training data. Select a region from [here](https://cloud.google.com/ml-engine/docs/regions) or use the default '`us-central1`'.\n",
    "* `runtime-version` - The version of Cloud ML Engine to use for the job. If you don't specify a runtime version, the training service uses the default Cloud ML Engine runtime version 1.0. See the list of runtime versions for more information.\n",
    "* `python-version` - The Python version to use for the job. Python 3.5 is available with runtime version 1.4 or greater. If you don't specify a Python version, the training service uses Python 2.7.\n",
    "* `scale-tier` - A scale tier specifying the type of processing cluster to run your job on. This can be the CUSTOM scale tier, in which case you also explicitly specify the number and type of machines to use.\n",
    "\n",
    "Note: Check to make sure gcloud is set to the current PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\r\n"
     ]
    }
   ],
   "source": [
    "! gcloud config set project $PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: JOBNAME=census_training_20190408_110644\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "JOBNAME = 'census_training_'\n",
    "JOBNAME += datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "%env JOBNAME $JOBNAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "census_training_20190408_110644\r\n"
     ]
    }
   ],
   "source": [
    "!echo $JOBNAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit the training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job [census_training_20190408_110644] submitted successfully.\r\n",
      "Your job is still active. You may view the status of your job with the command\r\n",
      "\r\n",
      "  $ gcloud ml-engine jobs describe census_training_20190408_110644\r\n",
      "\r\n",
      "or continue streaming the logs with the command\r\n",
      "\r\n",
      "  $ gcloud ml-engine jobs stream-logs census_training_20190408_110644\r\n",
      "jobId: census_training_20190408_110644\r\n",
      "state: QUEUED\r\n"
     ]
    }
   ],
   "source": [
    "! gcloud ml-engine jobs submit training $JOBNAME \\\n",
    "  --job-dir $JOB_DIR \\\n",
    "  --package-path $TRAINER_PACKAGE_PATH \\\n",
    "  --module-name $MAIN_TRAINER_MODULE \\\n",
    "  --region $REGION \\\n",
    "  --runtime-version=$RUNTIME_VERSION \\\n",
    "  --python-version=$PYTHON_VERSION \\\n",
    "  --scale-tier BASIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "createTime: '2019-04-03T13:24:36Z'\r\n",
      "endTime: '2019-04-03T13:29:07Z'\r\n",
      "etag: ESL4uGCPn3g=\r\n",
      "jobId: census_training_20190403_152433\r\n",
      "startTime: '2019-04-03T13:25:23Z'\r\n",
      "state: SUCCEEDED\r\n",
      "trainingInput:\r\n",
      "  jobDir: gs://ml-productive-pipeline-53122/scikit_learn_job_dir\r\n",
      "  packageUris:\r\n",
      "  - gs://ml-productive-pipeline-53122/scikit_learn_job_dir/packages/8dde0283dc3d080f53da3cad00639cabf1c12f20d313c09121746b9f0a086782/census_training-0.0.0.tar.gz\r\n",
      "  pythonModule: census_training.train\r\n",
      "  pythonVersion: '3.5'\r\n",
      "  region: europe-west1\r\n",
      "  runtimeVersion: '1.13'\r\n",
      "trainingOutput:\r\n",
      "  consumedMLUnits: 0.07\r\n",
      "\r\n",
      "View job in the Cloud Console at:\r\n",
      "https://console.cloud.google.com/ml/jobs/census_training_20190403_152433?project=ml-productive-pipeline-53122\r\n",
      "\r\n",
      "View logs at:\r\n",
      "https://console.cloud.google.com/logs?resource=ml.googleapis.com%2Fjob_id%2Fcensus_training_20190403_152433&project=ml-productive-pipeline-53122\r\n"
     ]
    }
   ],
   "source": [
    "!gcloud ml-engine jobs describe census_training_20190403_152433"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!gcloud ml-engine jobs stream-logs census_training_20190403_152433"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verify Model File in GCS\n",
    "View the contents of the destination model folder to verify that model file has indeed been uploaded to GCS.\n",
    "\n",
    "Note: The model can take a few minutes to train and show up in GCS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://ml-productive-pipeline-53122/scikit_learn/census_20190403_132638/model.joblib\r\n"
     ]
    }
   ],
   "source": [
    "! gsutil ls gs://$BUCKET_NAME/scikit_learn/census_*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use model with Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test your model with local predictions\n",
    "\n",
    "- local environment has to match selected [runtime](https://cloud.google.com/ml-engine/docs/tensorflow/runtime-version-list)\n",
    "- see [documentation](https://cloud.google.com/ml-engine/docs/scikit/using-pipelines-for-preprocessing#test_your_model_with_local_predictions)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: MODEL_DIR=gs://{cfg['bucket']}/scikit_learn/{JOBNAME}/\n",
      "env: MODEL_DIR=gs://ml-productive-pipeline-53122/scikit_learn/census_20190403_132638/\n",
      "env: INPUT_FILE=/home/enryh/gcp_poc/project/data/census/test_inputs.json\n",
      "env: FRAMEWORK=SCIKIT_LEARN\n"
     ]
    }
   ],
   "source": [
    "%env MODEL_DIR gs://{cfg['bucket']}/scikit_learn/{JOBNAME}/\n",
    "%env MODEL_DIR gs://{cfg['bucket']}/scikit_learn/census_20190403_132638/ \n",
    "pwd = %pwd\n",
    "INPUT_FILE=pwd + '/data/census/test_inputs.json'\n",
    "%env INPUT_FILE $INPUT_FILE\n",
    "FRAMEWORK=\"SCIKIT_LEARN\"\n",
    "%env FRAMEWORK $FRAMEWORK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create some inputs\n",
    "\n",
    "- ten first inputs from `data/census/adult.test` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|1x3 Cross validator\r\n",
      "25, Private, 226802, 11th, 7, Never-married, Machine-op-inspct, Own-child, Black, Male, 0, 0, 40, United-States, <=50K.\r\n",
      "38, Private, 89814, HS-grad, 9, Married-civ-spouse, Farming-fishing, Husband, White, Male, 0, 0, 50, United-States, <=50K.\r\n",
      "28, Local-gov, 336951, Assoc-acdm, 12, Married-civ-spouse, Protective-serv, Husband, White, Male, 0, 0, 40, United-States, >50K.\r\n",
      "44, Private, 160323, Some-college, 10, Married-civ-spouse, Machine-op-inspct, Husband, Black, Male, 7688, 0, 40, United-States, >50K.\r\n",
      "18, ?, 103497, Some-college, 10, Never-married, ?, Own-child, White, Female, 0, 0, 30, United-States, <=50K.\r\n",
      "34, Private, 198693, 10th, 6, Never-married, Other-service, Not-in-family, White, Male, 0, 0, 30, United-States, <=50K.\r\n",
      "29, ?, 227026, HS-grad, 9, Never-married, ?, Unmarried, Black, Male, 0, 0, 40, United-States, <=50K.\r\n",
      "63, Self-emp-not-inc, 104626, Prof-school, 15, Married-civ-spouse, Prof-specialty, Husband, White, Male, 3103, 0, 32, United-States, >50K.\r\n",
      "24, Private, 369667, Some-college, 10, Never-married, Other-service, Unmarried, White, Female, 0, 0, 40, United-States, <=50K.\r\n",
      "55, Private, 104996, 7th-8th, 4, Married-civ-spouse, Craft-repair, Husband, White, Male, 0, 0, 10, United-States, <=50K.\r\n"
     ]
    }
   ],
   "source": [
    "!head -11 data/census/adult.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_label = [False, False, True, True, False, False, False, True, False, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /home/enryh/gcp_poc/project/data/census/test_inputs.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile $INPUT_FILE\n",
    "[25, \"Private\", 226802, \"11th\", 7, \"Never-married\", \"Machine-op-inspct\", \"Own-child\", \"Black\", \"Male\", 0, 0, 40, \"United-States\"]\n",
    "[38, \"Private\", 89814, \"HS-grad\", 9, \"Married-civ-spouse\", \"Farming-fishing\", \"Husband\", \"White\", \"Male\", 0, 0, 50, \"United-States\"]\n",
    "[28, \"Local-gov\", 336951, \"Assoc-acdm\", 12, \"Married-civ-spouse\", \"Protective-serv\", \"Husband\", \"White\", \"Male\", 0, 0, 40, \"United-States\"]\n",
    "[44, \"Private\", 160323, \"Some-college\", 10, \"Married-civ-spouse\", \"Machine-op-inspct\", \"Husband\", \"Black\", \"Male\", 7688, 0, 40, \"United-States\"]\n",
    "[18, \"?\", 103497, \"Some-college\", 10, \"Never-married\", \"?\", \"Own-child\", \"White\", \"Female\", 0, 0, 30, \"United-States\"]\n",
    "[34, \"Private\", 198693, \"10th\", 6, \"Never-married\", \"Other-service\", \"Not-in-family\", \"White\", \"Male\", 0, 0, 30, \"United-States\"]\n",
    "[29, \"?\", 227026, \"HS-grad\", 9, \"Never-married\", \"?\", \"Unmarried\", \"Black\", \"Male\", 0, 0, 40, \"United-States\"]\n",
    "[63, \"Self-emp-not-inc\", 104626, \"Prof-school\", 15, \"Married-civ-spouse\", \"Prof-specialty\", \"Husband\", \"White\", \"Male\", 3103, 0, 32, \"United-States\"]\n",
    "[24, \"Private\", 369667, \"Some-college\", 10, \"Never-married\", \"Other-service\", \"Unmarried\", \"White\", \"Female\", 0, 0, 40, \"United-States\"]\n",
    "[55, \"Private\", 104996, \"7th-8th\", 4, \"Married-civ-spouse\", \"Craft-repair\", \"Husband\", \"White\", \"Male\", 0, 0, 10, \"United-States\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sumit Inputs to model locally to machine which is running the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33mWARNING:\u001b[0m Copying gs://ml-productive-pipeline-53122/scikit_learn/census_20190403_132638/model.joblib...\r\n",
      "/ [0 files][    0.0 B/  7.7 MiB]                                                \r",
      "-\r",
      "- [0 files][528.0 KiB/  7.7 MiB]                                                \r",
      "\\\r",
      "\\ [0 files][792.0 KiB/  7.7 MiB]                                                \r",
      "|\r",
      "| [0 files][  1.0 MiB/  7.7 MiB]                                                \r",
      "/\r",
      "/ [0 files][  1.3 MiB/  7.7 MiB]                                                \r",
      "-\r",
      "- [0 files][  1.6 MiB/  7.7 MiB]                                                \r",
      "\\\r",
      "|\r",
      "| [0 files][  2.6 MiB/  7.7 MiB]                                                \r",
      "/\r",
      "/ [0 files][  5.4 MiB/  7.7 MiB]    1.2 MiB/s                                   \r",
      "-\r",
      "\\\r",
      "\\ [0 files][  6.7 MiB/  7.7 MiB]    1.1 MiB/s                                   \r",
      "|\r",
      "/\r",
      "/ [0 files][  7.7 MiB/  7.7 MiB]    1.3 MiB/s                                   \r",
      "/ [1 files][  7.7 MiB/  7.7 MiB]    1.3 MiB/s                                   \r",
      "\r\n",
      "Operation completed over 1 objects/7.7 MiB.                                      \r\n",
      "\r\n",
      "[False, False, False, True, False, False, False, False, False, False]\r\n"
     ]
    }
   ],
   "source": [
    "!gcloud ml-engine local predict --model-dir $MODEL_DIR \\\n",
    "   --json-instances $INPUT_FILE \\\n",
    "   --framework $FRAMEWORK "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy Model\n",
    "- using `gcloud ml-engine`\n",
    "- set Environment Variables: `MODEL_NAME`, `VERSION_NAME`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created ml engine model [projects/ml-productive-pipeline-53122/models/SKLEARN_CENSUS].\r\n"
     ]
    }
   ],
   "source": [
    "%env VERSION_NAME v1\n",
    "%env MODEL_NAME SKLEARN_CENSUS\n",
    "\n",
    "# Create a Model resource\n",
    "!gcloud ml-engine models create $MODEL_NAME --regions $REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: VERSION_NAME=v1\n",
      "env: MODEL_NAME=SKLEARN_CENSUS\n",
      "Creating version (this might take a few minutes)......done.                     \n"
     ]
    }
   ],
   "source": [
    "#Create a Model version\n",
    "!gcloud ml-engine versions create $VERSION_NAME \\\n",
    "  --model $MODEL_NAME \\\n",
    "  --origin $MODEL_DIR \\\n",
    "  --runtime-version=1.13 \\\n",
    "  --framework $FRAMEWORK \\\n",
    "  --python-version=3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "createTime: '2019-04-08T09:43:56Z'\n",
      "deploymentUri: gs://ml-productive-pipeline-53122/scikit_learn/census_20190403_132638/\n",
      "etag: -LrjegP6db8=\n",
      "framework: SCIKIT_LEARN\n",
      "isDefault: true\n",
      "lastUseTime: '2019-04-08T11:05:31Z'\n",
      "machineType: mls1-c1-m2\n",
      "name: projects/ml-productive-pipeline-53122/models/SKLEARN_CENSUS/versions/v1\n",
      "pythonVersion: '3.5'\n",
      "runtimeVersion: '1.13'\n",
      "state: READY\n"
     ]
    }
   ],
   "source": [
    "!gcloud ml-engine versions describe $VERSION_NAME \\\n",
    "  --model $MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False, False, False, True, False, False, False, False, False, False]\r\n"
     ]
    }
   ],
   "source": [
    "!gcloud ml-engine predict --model $MODEL_NAME --version \\\n",
    "  $VERSION_NAME --json-instances $INPUT_FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse results and check correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = !gcloud ml-engine predict --model $MODEL_NAME --version \\\n",
    "  $VERSION_NAME --json-instances $INPUT_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False, False, False, True, False, False, False, False, False, False]\n"
     ]
    }
   ],
   "source": [
    "print(result[0])\n",
    "result=[x==\"True\" for x in result[0].strip(\"[]\").split(\", \")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: False, Label: False\n",
      "Predicted: False, Label: False\n",
      "Predicted: False, Label: True\n",
      "Predicted: True, Label: True\n",
      "Predicted: False, Label: False\n",
      "Predicted: False, Label: False\n",
      "Predicted: False, Label: False\n",
      "Predicted: False, Label: True\n",
      "Predicted: False, Label: False\n",
      "Predicted: False, Label: False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for predicted, correct in zip(result, correct_label):\n",
    "    print(\"Predicted: {prediction}, Label: {label}\".format(prediction=predicted, label=correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7, 0],\n",
       "       [2, 1]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.metrics as sklm\n",
    "sklm.confusion_matrix(correct_label, result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"createTime: '2019-04-08T09:43:56Z'\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_desc = !gcloud ml-engine versions describe $VERSION_NAME \\\n",
    "  --model $MODEL_NAME\n",
    "model_desc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'createTime': \"'2019-04-08T09:43:56Z'\",\n",
       " 'deploymentUri': 'gs://ml-productive-pipeline-53122/scikit_learn/census_20190403_132638/',\n",
       " 'etag': '-LrjegP6db8=',\n",
       " 'framework': 'SCIKIT_LEARN',\n",
       " 'isDefault': 'true',\n",
       " 'lastUseTime': \"'2019-04-08T09:48:08Z'\",\n",
       " 'machineType': 'mls1-c1-m2',\n",
       " 'name': 'projects/ml-productive-pipeline-53122/models/SKLEARN_CENSUS/versions/v1',\n",
       " 'pythonVersion': \"'3.5'\",\n",
       " 'runtimeVersion': \"'1.13'\",\n",
       " 'state': 'READY'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "model_desc_dict = {}\n",
    "x = model_desc[0].split(\": \")\n",
    "for x in model_desc:\n",
    "    x = x.split(\": \")\n",
    "    model_desc_dict[x[0]] = x[1]\n",
    "model_desc_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gcp_dl",
   "language": "python",
   "name": "gcp_dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
